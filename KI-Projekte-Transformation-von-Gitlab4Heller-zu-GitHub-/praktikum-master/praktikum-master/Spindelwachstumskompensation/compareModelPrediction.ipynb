{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare new model with prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the prediction of a new model with the prediction of the model in the app based on defined validation data\n",
    "- Need to provide:\n",
    "    - a path to the validation data as csv files\n",
    "    - a path to a pipeline which should be used to transform the validation data\n",
    "    - a path to the model which should be compared with the online prediction\n",
    "    - The data will be transformed into the format expected by the lstm, specify using window and shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"X:\\\\KI Praktikum\\\\validate_Data\\\\2023_08_23_filtered_data\\\\interpoliert\"\n",
    "parameters = [\"t_bett\", \"t_motor\", \"t_spindle\", \"M8\", \"M121\", \"M127\", \"M7\"]\n",
    "pipePath = \"X:\\\\KI Praktikum\\\\pipeline.p\"\n",
    "modelPath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\training_data\\\\23-09-08_model_train_s6_w60_maxErr-9-44.h5\"\n",
    "window = 60\n",
    "shift = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from joblib import dump, load\n",
    " \n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, GRU, LSTM\n",
    "from keras.activations import relu, tanh, linear\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, TerminateOnNaN\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weightedValues import weightValues\n",
    "from readIn import readIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateDataSource() -> 3D array von den Daten\n",
    "### window  represents time period by each entry in the buffer\n",
    "### Shift represents the jump from value to next one in the buffer\n",
    "### sampling rate\n",
    "\n",
    "def generateDataSource(signal_input=None, input_columns: list = [], output_length: int = 1, signal_output=None, window=1, shift=1, sample_rate=1):\n",
    "    #subsequence_len= (window -1) *shift + 1\n",
    "    subsequence_len= (window) *shift\n",
    "    Signal_Length = signal_input.shape[0]\n",
    "    num_samples = 1 + int((Signal_Length - subsequence_len) / sample_rate)\n",
    "    x = np.zeros(shape=(num_samples, window, signal_input.shape[1]))\n",
    "    y = np.zeros(shape=(num_samples, output_length, 1))\n",
    "    for i in range(num_samples):\n",
    "        x[i] = np.asarray([signal_input[i*sample_rate + j * shift] for j in range(0,window)])\n",
    "        y[i] = signal_output[i*sample_rate + (window-1) * shift :i*sample_rate+ (window-1) * shift + output_length]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_val_data = readIn(dataPath, False, False)\n",
    "#print(df_val_data.tail(3))\n",
    "\n",
    "y_validation = 1000*df_val_data[\"welle_z_ipo\"]\n",
    "x_validation = df_val_data[parameters].to_numpy()\n",
    "prediction = 1000*df_val_data[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = load(pipePath)\n",
    "model = tf.keras.models.load_model(modelPath, compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = pipeline.transform(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation, y_validation = generateDataSource(signal_input = x_validation, signal_output = y_validation, window = window, shift = shift, sample_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The validation data needs to be adapted to be fed into the lstm model\n",
    "# Therefore not all values are used.\n",
    "# To make the lstm model comparable to the online model, the compared\n",
    "# predictions need to match the dimensions\n",
    "sample_rate = 1\n",
    "subsequence_len= (window) *shift\n",
    "Signal_Length = prediction.shape[0]\n",
    "num_samples = 1 + int((Signal_Length - subsequence_len) / sample_rate)\n",
    "\n",
    "p = np.zeros(shape=(num_samples, 1, 1))\n",
    "for i in range(num_samples):\n",
    "    p[i] = prediction[i*sample_rate + (window-1) * shift :i*sample_rate+ (window-1) * shift + 1]\n",
    "prediction = p[:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_validation[:,0,0]\n",
    "y_pred = model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as ex\n",
    "import plotly.io as pio\n",
    "\n",
    "scatter_mode= 'markers'\n",
    "\n",
    "nrrows = 1\n",
    "fig= make_subplots(rows=nrrows, cols=1, shared_xaxes= True, print_grid= True, vertical_spacing=0.01)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = y_validation, y = y_pred.flatten(), name= \"y_pred\", mode= scatter_mode), row= 1, col= 1)\n",
    "fig.add_trace(go.Scatter(x = y_validation, y = prediction, name= \"y_online\", mode= scatter_mode), row= 1, col= 1)\n",
    "fig.add_trace(go.Scatter(x = y_validation, y = y_validation, name= \"optimal line\", mode=\"lines\"), row= 1, col= 1)\n",
    "fig.add_trace(go.Scatter(x = (y_validation), y = (y_validation+5), name= \"Upper bound\", mode=\"lines\", line_color = \"black\"), row= 1, col= 1)\n",
    "fig.add_trace(go.Scatter(x = (y_validation), y = (y_validation-5), name= \"Lower bound\", mode=\"lines\", line_color=\"black\"), row= 1, col= 1)\n",
    "#fig.add_trace(go.Scatter(y = y_validation, name= \"y_true\", mode= scatter_mode), row= 1, col= 1)\n",
    "\n",
    "fig.update_layout(height=700, width=800, title_text=\"Compare prediction by my model and model on the machine\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_err_online = tf.keras.losses.mean_absolute_error(prediction, y_validation)\n",
    "abs_err_model = tf.keras.losses.mean_absolute_error(y_pred.flatten(), y_validation)\n",
    "print(\"abs_err_online: \", abs_err_online)\n",
    "print(\"abs_err_model: \", abs_err_model)\n",
    "\n",
    "differenceModel = y_validation - y_pred.flatten()\n",
    "differenceOnline = y_validation - prediction\n",
    "max_err_online = max(abs(differenceOnline))\n",
    "max_err_model = max(abs(differenceModel))\n",
    "print(\"max_err_online: \", max_err_online)\n",
    "print(\"max_err_model: \", max_err_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_mode= 'lines'\n",
    "\n",
    "nrrows = 1\n",
    "fig= make_subplots(rows=nrrows, cols=1, shared_xaxes= True, print_grid= True, vertical_spacing=0.01)\n",
    "\n",
    "fig.add_trace(go.Scatter(y = y_pred.flatten(), name= \"y_pred\", mode= scatter_mode), row= 1, col= 1)\n",
    "fig.add_trace(go.Scatter(y = prediction, name= \"y_online\", mode= scatter_mode), row= 1, col= 1)\n",
    "fig.add_trace(go.Scatter(y = y_validation,  name= \"validation\", mode=\"lines\"), row= 1, col= 1)\n",
    "# fig.add_trace(go.Scatter(x = (y_validation), y = (y_validation+5), name= \"Upper bound\", mode=\"lines\", line_color = \"black\"), row= 1, col= 1)\n",
    "# fig.add_trace(go.Scatter(x = (y_validation), y = (y_validation-5), name= \"Lower bound\", mode=\"lines\", line_color=\"black\"), row= 1, col= 1)\n",
    "#fig.add_trace(go.Scatter(y = y_validation, name= \"y_true\", mode= scatter_mode), row= 1, col= 1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200, title_text=\"Compare prediction by my model and model on the machine\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
