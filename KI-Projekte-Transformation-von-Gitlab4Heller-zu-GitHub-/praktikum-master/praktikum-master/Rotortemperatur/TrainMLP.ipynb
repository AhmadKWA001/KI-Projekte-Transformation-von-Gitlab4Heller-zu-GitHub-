{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, GRU, LSTM\n",
    "from keras.activations import relu, tanh, linear\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN, ModelCheckpoint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonTrain\\\\Versuche08-12_09_2023_train.csv\"\n",
    "valPath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonVal\\\\Versuche08-12_09_2023_val.csv\"\n",
    "pipePath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\pipelineMLP.p\"\n",
    "filepath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\cvModel.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(trainPath)\n",
    "df_val = pd.read_csv(valPath)\n",
    "\n",
    "y_train = df_train[\"No.6\"]\n",
    "parameters = [\"T_KLEMMUNG\", \"T_LAGER\", \"DRZ5\", \"T_MOTOR\", \"I_FELD\", \"V_QUER\"]\n",
    "x_train = df_train[parameters].to_numpy()\n",
    "\n",
    "y_val = df_val[\"No.6\"]\n",
    "x_val = df_val[parameters].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_steps = [(\"standardize_values\", StandardScaler()), (\"pca\", PCA(6)), (\"standard_values\", StandardScaler())]\n",
    "pipeline = Pipeline(steps=seq_steps)\n",
    "dump(pipeline, pipePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpipeline = load(pipePath)\n",
    "x_transform = newpipeline.fit_transform(x_train)\n",
    "x_test = newpipeline.transform(x_val)\n",
    "newpipeline.steps[1][1].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='val_loss', patience=100, verbose =1, mode = \"auto\")\n",
    "stopNaN = TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_model(layers=[5, 5, 5], dropout=0, activation = \"relu\", optimizer=\"Nadam\", first_activ = \"relu\"):\n",
    "    model = Sequential()\n",
    "    first = True\n",
    "    for layer in layers:\n",
    "        if first:\n",
    "            model.add(Dense(layer, activation=first_activ, input_dim=6))\n",
    "            first = False\n",
    "        else:\n",
    "            model.add(Dense(layer, activation=activation))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=ks.losses.mean_absolute_error)\n",
    "    # return compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "model = KerasRegressor(build_fn=get_mlp_model, verbose=1, layers=[5, 5, 5], dropout=0, activation = \"relu\", optimizer=\"Nadam\", first_activ = \"relu\")     \n",
    "                    #, first_rec_activ=\"sigmoid\", rec_activ=\"sigmoid\"\n",
    "#model.fit(x_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict( \n",
    "    layers = [[5], [10, 5], [500, 500, 300], [100, 150, 50], \n",
    "            [700, 500, 300], [700, 700, 500]],    #[500, 400, 200], [700, 700, 500, 300], [700, 700, 500, 100],[25, 25, 25, 20, 20, 20, 10, 10],  [75, 75, 50, 50, 50, 40, 40, 20]\n",
    "    dropout = [0, 0.1, 0.3, 0.2],\n",
    "    first_activ = [\"relu\", \"tanh\"],\n",
    "    activation = [\"relu\", \"tanh\"],\n",
    "    #first_rec_activ = [\"sigmoid\", \"tanh\"],\n",
    "    #rec_activ = [\"sigmoid\", \"tanh\"],\n",
    "    optimizer = [\"Nadam\", \"Adam\"]\n",
    "    #losses = [tf.keras.losses.mean_squared_error, tf.keras.losses.mean_absolute_error]\n",
    ")\n",
    "\n",
    "searcher = RandomizedSearchCV(estimator=model, n_jobs=1, #cv=[[x_transform, y_train], [x_test, y_val]],\n",
    "    param_distributions=grid, scoring='neg_mean_absolute_error', n_iter = 5)\n",
    "searchResults = searcher.fit(x_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore, bestParams))\n",
    "\n",
    "bestModel = searchResults.best_estimator_\n",
    "bestModel.fit(x_transform, y_train)\n",
    "score = bestModel.score(x_val, y_val)\n",
    "print(\"score: {:.2f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred = bestModel.predict(x_val)\n",
    "y_pred_train = bestModel.predict(x_train)\n",
    "error_avg = np.mean(abs(y_val - best_pred))\n",
    "error_max = max(abs(y_val - best_pred))\n",
    "print(\"max: \", error_max)\n",
    "print(\"avg: \", error_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_test = y_val - best_pred\n",
    "error_avg_test = np.mean(abs(diff_test))\n",
    "error_max_test = np.max(abs(diff_test))\n",
    "\n",
    "diff_train = y_train - y_pred_train\n",
    "error_avg_train = np.mean(abs(diff_train))\n",
    "error_max_train = np.max(abs(diff_train))\n",
    "\n",
    "#mean_absolute = tf.keras.losses.mean_absolute_error(y_cv[:,0], y_pred.flatten())\n",
    "#print(\"mean absolute: \", mean_absolute)\n",
    "print(\"Validation scores: \")\n",
    "print(\"max error: \", error_max_test)\n",
    "print(\"mean abs error: \", error_avg_test)\n",
    "print(\"Error over the training data: \")\n",
    "print(\"max error: \", error_max_train)\n",
    "print(\"mean abs error: \", error_avg_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
