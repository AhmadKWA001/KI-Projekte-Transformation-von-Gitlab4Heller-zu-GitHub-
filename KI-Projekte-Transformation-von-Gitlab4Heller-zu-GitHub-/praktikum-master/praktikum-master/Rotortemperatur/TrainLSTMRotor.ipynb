{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a defined LSTM using prepsocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in one or several json files. Use them to train a specified LSTM.\n",
    "\n",
    "It is expected, that the read in data is already preprocessed, no pipeline is needed, but the \n",
    "\n",
    "goal values are weighted depending on the amount of samples within the respective bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    " \n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, GRU, LSTM\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, TerminateOnNaN, ModelCheckpoint\n",
    "import json\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weightedValues import weightValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenJsontoArr(path):\n",
    "    file = open(path)\n",
    "    x_3d = json.load(file)\n",
    "    file.close()\n",
    "    x_3d = np.asarray(x_3d)\n",
    "    return x_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(layers, dropout, activation, input_shape, loss):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape))\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        if i == len(layers)-1:\n",
    "            model.add(LSTM(layers[i], stateful = False, dropout=dropout, activation = activation, return_sequences=False))\n",
    "        else:\n",
    "            model.add(LSTM(layers[i], stateful = False, dropout=dropout, activation = activation, return_sequences=True))\n",
    "        #model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1, activation=\"relu\"))\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        loss= loss,\n",
    "        #metrics=[ \"max_loss\"],\n",
    "        optimizer = \"Adam\")\n",
    "    # return compiled model\n",
    "\n",
    "    print(model.layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Custom loss function to reduce the absolute error of the individual sample as well as the \n",
    "maximum error\"\"\"\n",
    "def customLoss(y_true, y_pred):\n",
    "    weight = 1.5\n",
    "    difference = tf.abs(y_true - y_pred)\n",
    "    exponent = tf.exp(tf.multiply(weight, difference))\n",
    "    weighted_muls = tf.multiply(difference, exponent)\n",
    "    boltzmann_op = tf.reduce_sum(weighted_muls) / tf.reduce_sum(exponent)\n",
    "    loss = tf.add(boltzmann_op, tf.losses.mean_absolute_error(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(x_train, x_test, y_train, y_test):\n",
    "    x_trainAll = np.array([]).reshape(0, 40, 6)\n",
    "    y_trainAll = np.array([]).reshape(0,)\n",
    "    x_testAll = np.array([]).reshape(0, 40, 6)\n",
    "    y_testAll = np.array([]).reshape(0,)\n",
    "\n",
    "    min_seq_length = 100000\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        x_trainfile = OpenJsontoArr(x_train[i])\n",
    "\n",
    "        if len(x_trainfile) < min_seq_length:\n",
    "            min_seq_length = len(x_trainfile)\n",
    "\n",
    "        x_testfile = OpenJsontoArr(x_test[i])\n",
    "        x_trainfile = np.nan_to_num(x_trainfile)\n",
    "        x_testfile = np.nan_to_num(x_testfile)\n",
    "        y_trainfile = OpenJsontoArr(y_train[i])\n",
    "        y_testfile = OpenJsontoArr(y_test[i])\n",
    "        y_trainfile = y_trainfile.flatten()\n",
    "        y_testfile = y_testfile.flatten()\n",
    "        x_trainAll = np.concatenate((x_trainAll, x_trainfile))\n",
    "        x_testAll = np.concatenate((x_testAll, x_testfile))\n",
    "        y_trainAll = np.concatenate((y_trainAll, y_trainfile))\n",
    "        y_testAll = np.concatenate((y_testAll, y_testfile))\n",
    "\n",
    "    df_y_train = pd.DataFrame({\"y\": y_trainAll})\n",
    "    df_weights_train = weightValues(df_y_train, weightMin=1, weightMax=1, namey=\"y\", nameWeights=\"weights\")\n",
    "    df_y_test = pd.DataFrame({\"y\": y_testAll})\n",
    "    df_weights_test = weightValues(df_y_test, weightMin=1, weightMax=1, namey=\"y\", nameWeights=\"weights\")\n",
    "\n",
    "    y_testAll = np.array(df_weights_test)\n",
    "    y_testAll = y_testAll[:, :2]\n",
    "    y_trainAll = np.array(df_weights_train)\n",
    "    y_trainAll = y_trainAll[:, :2]\n",
    "\n",
    "    return x_trainAll, x_testAll, y_trainAll, y_testAll, min_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='val_loss', patience=300, verbose =1, mode = \"auto\")\n",
    "#csvLogger = CSVLogger('X:\\\\KI Praktikum\\\\csvLoggerCustomLoss.xlsx')\n",
    "stopNaN = TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to plot the prediction compared with the real y-values'''\n",
    "\n",
    "def plotPredError(y_pred, y_true):\n",
    "    scatter_mode = 'lines'\n",
    "\n",
    "    fig= make_subplots(rows=1, cols=1, shared_xaxes= True, print_grid= True)\n",
    "\n",
    "    fig.add_trace(go.Scatter(y= y_pred.flatten(), name= 'prediction', mode= scatter_mode), row= 1, col= 1)\n",
    "    fig.add_trace(go.Scatter(y= y_true.flatten(), name= 'trace', mode= scatter_mode), row= 1, col= 1)\n",
    "    fig.update_yaxes(title_text= 'y-value', row= 1, col= 1)\n",
    "\n",
    "    fig.update_layout(height=600, width=1200, title_text=\"Prediction error\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLSTM(x_train, x_test, y_train, y_test, window, modelpath, batch_size):\n",
    "    #i = 0\n",
    "    #summary = np.array(len(losses))\n",
    "    #for loss in losses:\n",
    "    checkpoint = ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    lstmmodel = get_lstm_model(layers=[5], dropout=0, activation = \"tanh\", input_shape = (window, 6), loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    summary = lstmmodel.fit(x=x_train, y=y_train[:,0], validation_data=(x_test, y_test[:,0]), sample_weight = y_train[:,1], \n",
    "                            epochs = 1000, batch_size = batch_size, callbacks=[earlyStop, stopNaN, checkpoint], shuffle = False, verbose = 0)\n",
    "\n",
    "    y_pred_test = lstmmodel.predict(x_test)\n",
    "    y_pred_train = lstmmodel.predict(x_train)\n",
    "\n",
    "    diff_test = y_test[:,0] - y_pred_test.flatten()\n",
    "    error_avg_test = np.mean(abs(diff_test))\n",
    "    error_max_test = np.max(abs(diff_test))\n",
    "\n",
    "    diff_train = y_train[:,0] - y_pred_train.flatten()\n",
    "    error_avg_train = np.mean(abs(diff_train))\n",
    "    error_max_train = np.max(abs(diff_train))\n",
    "\n",
    "    #mean_absolute = tf.keras.losses.mean_absolute_error(y_cv[:,0], y_pred.flatten())\n",
    "    #print(\"mean absolute: \", mean_absolute)\n",
    "    print(\"Validation scores: \")\n",
    "    print(\"max error: \", error_max_test)\n",
    "    print(\"mean abs error: \", error_avg_test)\n",
    "    print(\"Error over the training data: \")\n",
    "    print(\"max error: \", error_max_train)\n",
    "    print(\"mean abs error: \", error_avg_train)\n",
    "    #i+=1\n",
    "\n",
    "    plotPredError(y_pred_test, y_test[:,0])\n",
    "    plotPredError(y_pred_train, y_train[:,0])\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainValLoss(summary):\n",
    "    scatter_mode = \"lines\"\n",
    "    train_loss = summary.history[\"loss\"]\n",
    "    validation_loss = summary.history[\"val_loss\"]\n",
    "\n",
    "    fig= make_subplots(rows=1, cols=1, shared_xaxes= True, print_grid= True)\n",
    "\n",
    "    fig.add_trace(go.Scatter( y= train_loss, name= 'training loss', mode= scatter_mode), row= 1, col= 1)\n",
    "    fig.add_trace(go.Scatter( y= validation_loss, name= 'validation loss', mode= scatter_mode), row= 1, col= 1)\n",
    "    fig.update_yaxes(title_text= 'loss', row= 1, col= 1)\n",
    "\n",
    "    fig.update_layout(height=600, width=1200, title_text=\"Training loss curve\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = glob.glob(os.path.join(\"X:\\\\RotorTempKI\\\\train\", \"*_x.json\"))\n",
    "# y_train = glob.glob(os.path.join(\"X:\\\\RotorTempKI\\\\train\", \"*_y.json\"))\n",
    "# x_test = glob.glob(os.path.join(\"X:\\\\RotorTempKI\\\\validation\", \"*_x.json\"))\n",
    "# y_test = glob.glob(os.path.join(\"X:\\\\RotorTempKI\\\\validation\", \"*_y.json\"))\n",
    "# window_size = [50, 60, 70, 50, 60, 70, 50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(x_train)):\n",
    "#     print(x_train[i])\n",
    "#     x_traini, x_testi, y_traini, y_testi = preprocessData(x_train[i], x_test[i], y_train[i], y_test[i])\n",
    "#     summary = trainLSTM(x_traini, x_testi, y_traini, y_testi, window_size[i])\n",
    "#     plotTrainValLoss(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonTrain\", \"*_x.json\"))\n",
    "y_train = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonTrain\", \"*_y.json\"))\n",
    "x_test = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonVal\", \"*_x.json\"))\n",
    "y_test = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonVal\", \"*_y.json\"))\n",
    "window_size = [40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data:\n",
    "x_traini, x_testi, y_traini, y_testi, min_seq_length = preprocessData(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\modelle\\\\\" + \"14-09-23_s1_w40\" +\".h5\"\n",
    "print(filepath)\n",
    "\n",
    "x_train=x_traini\n",
    "x_test=x_testi\n",
    "y_train=y_traini\n",
    "y_test=y_testi\n",
    "window=window_size[0]\n",
    "modelpath = filepath\n",
    "batch_size = min_seq_length\n",
    "\n",
    "checkpoint = ModelCheckpoint(modelpath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "lstmmodel = get_lstm_model(layers=[10], dropout=0, activation = \"elu\", input_shape = (window, 6), loss = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "summary = lstmmodel.fit(x=x_train, y=y_train[:,0], validation_data=(x_test, y_test[:,0]), sample_weight = y_train[:,1], \n",
    "                        epochs = 2000, batch_size = batch_size, callbacks=[earlyStop, checkpoint], shuffle = False, verbose = 1)\n",
    "\n",
    "y_pred_test = lstmmodel.predict(x_test)\n",
    "y_pred_train = lstmmodel.predict(x_train)\n",
    "\n",
    "diff_test = y_test[:,0] - y_pred_test.flatten()\n",
    "error_avg_test = np.mean(abs(diff_test))\n",
    "error_max_test = np.max(abs(diff_test))\n",
    "\n",
    "diff_train = y_train[:,0] - y_pred_train.flatten()\n",
    "error_avg_train = np.mean(abs(diff_train))\n",
    "error_max_train = np.max(abs(diff_train))\n",
    "\n",
    "#mean_absolute = tf.keras.losses.mean_absolute_error(y_cv[:,0], y_pred.flatten())\n",
    "#print(\"mean absolute: \", mean_absolute)\n",
    "print(\"Validation scores: \")\n",
    "print(\"max error: \", error_max_test)\n",
    "print(\"mean abs error: \", error_avg_test)\n",
    "print(\"Error over the training data: \")\n",
    "print(\"max error: \", error_max_train)\n",
    "print(\"mean abs error: \", error_avg_train)\n",
    "#i+=1\n",
    "\n",
    "plotPredError(y_pred_test, y_test[:,0])\n",
    "plotPredError(y_pred_train, y_train[:,0])\n",
    "\n",
    "\n",
    "plotTrainValLoss(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(x_train)):\n",
    "filepath = \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\modelle\\\\\" + \"14-09-23_s1_w40\" +\".h5\"\n",
    "print(filepath)\n",
    "summary = trainLSTM(x_train=x_traini, x_test=x_testi, y_train=y_traini, y_test=y_testi, window=window_size[0], modelpath = filepath, batch_size = min_seq_length)\n",
    "plotTrainValLoss(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modell = load_model(filepath)\n",
    "# #summary = modell.fit(x_)\n",
    "# y_pred = modell.predict(x_testi)\n",
    "# y_diff = y_testi - y_pred\n",
    "# avg = np.mean(abs(y_diff))\n",
    "# max = np.max(abs(y_diff))\n",
    "# print(\"avg. error: \" + str(avg))\n",
    "# print(\"max. error: \" + str(max))\n",
    "# plotPredError(y_pred, y_testi[:,0])\n",
    "\n",
    "# y_pred_train = modell.predict(x_traini)\n",
    "# plotPredError(y_pred_train, y_traini[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
