{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV to LSTM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File to transform csv data into json files formatted for the training of a lstm.\n",
    "\n",
    "Within the file the column names needed for the magnet temperature are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import load, dump\n",
    "import json\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as ex\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from joblib import dump, load\n",
    " \n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, GRU, LSTM\n",
    "from keras.activations import relu, tanh, linear\n",
    "from keras.layers import Dropout\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, TerminateOnNaN\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readIn import readIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPath = \"X:\\\\RotorTempKI\\\\train\"\n",
    "valDataPath = \"X:\\\\RotorTempKI\\\\validation\"\n",
    "\n",
    "# Pipeline\n",
    "pathname = \"X:\\\\RotorTempKI\\\\pipeline.p\"\n",
    "\n",
    "filenames_train = [[\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s5_w50_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s5_w50_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s6_w50_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s6_w50_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s7_w50_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s7_w50_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s5_w60_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s5_w60_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s6_w60_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s6_w60_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s7_w60_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s7_w60_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s5_w70_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s5_w70_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s6_w70_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s6_w70_y.json\"],\n",
    "                   [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s7_w70_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\train\\\\train_s7_w70_y.json\"]]\n",
    "filenames_val = [[\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s5_w50_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s5_w50_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s6_w50_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s6_w50_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s7_w50_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s7_w50_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s5_w60_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s5_w60_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s6_w60_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s6_w60_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s7_w60_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s7_w60_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s5_w70_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s5_w70_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s6_w70_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s6_w70_y.json\"],\n",
    "                [\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s7_w70_x.json\", \"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\validation\\\\val_s7_w70_y.json\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateDataSource() -> 3D array von den Daten\n",
    "### window  represents time period by each entry in the buffer\n",
    "### Shift represents the jump from value to next one in the buffer\n",
    "### sampling rate\n",
    "\n",
    "def generateDataSource(signal_input=None, input_columns: list = [], output_length: int = 1, signal_output=None, window=1, shift=1, sample_rate=1):\n",
    "    #subsequence_len= (window -1) *shift + 1\n",
    "    subsequence_len= (window) *shift\n",
    "    Signal_Length = signal_input.shape[0]\n",
    "    num_samples = 1 + int((Signal_Length - subsequence_len) / sample_rate)\n",
    "    x = np.zeros(shape=(num_samples, window, signal_input.shape[1]))\n",
    "    y = np.zeros(shape=(num_samples, output_length, 1))\n",
    "    for i in range(num_samples):\n",
    "        x[i] = np.asarray([signal_input[i*sample_rate + j * shift] for j in range(0,window)])\n",
    "        y[i] = signal_output[i*sample_rate + (window-1) * shift :i*sample_rate+ (window-1) * shift + output_length]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Mustafas function\n",
    "def SaveJsonWindows(filenames, shift, window, x_transform, y_train, x_validation = None, y_validation = None):\n",
    "    i = 0\n",
    "    if x_validation != None:\n",
    "        x_in = np.concatenate((x_transform, x_validation))\n",
    "    else: \n",
    "        x_in = x_transform\n",
    "    if y_validation != None:\n",
    "        y_in = np.concatenate((y_train, y_validation))\n",
    "    else: \n",
    "        y_in = y_train\n",
    "\n",
    "    for w in window:\n",
    "        for s in shift:\n",
    "            x_cv, y_cv = generateDataSource(signal_input = x_in,\n",
    "                                            signal_output=y_in, \n",
    "                                            window = w, shift=s, sample_rate=1)\n",
    "            out_x = open(filenames[i][0], mode=\"x\")\n",
    "            json.dump(x_cv.tolist(), out_x)\n",
    "            out_x.close()\n",
    "            out_y = open(filenames[i][1], mode=\"x\")\n",
    "            json.dump(y_cv.tolist(), out_y)\n",
    "            out_y.close()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenJsontoArr(path):\n",
    "    file = open(path)           #\"X:\\\\KI Praktikum\\\\validate_Data\\\\3darray_x_cv.json\"\n",
    "    x_3d = json.load(file)\n",
    "    file.close()\n",
    "    x_3d = np.asarray(x_3d)\n",
    "    return x_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = readIn(trainDataPath)\n",
    "df_val = readIn(valDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.head(5))\n",
    "df_val = df_val.drop(columns=[\"start\", \"end\"])\n",
    "print(df_val.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"magnet_temperature\"]\n",
    "parameters = [\"T_KLEMMUNG\", \"T_LAGER\", \"DRZ5\", \"T_MOTOR\", \"I_FELD\", \"V_QUER\"]\n",
    "x_train = df_train[parameters].to_numpy()\n",
    "\n",
    "y_val = df_val[\"magnet_temperature\"]\n",
    "x_val = df_val[parameters].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_steps = [(\"standardize_values\", StandardScaler()), (\"pca\", PCA(6)), (\"standard_values\", StandardScaler())]\n",
    "pipeline = Pipeline(steps=seq_steps)\n",
    "dump(pipeline, pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpipeline = load(pathname)\n",
    "x_transform = newpipeline.fit_transform(x_train)\n",
    "x_test = newpipeline.transform(x_val)\n",
    "newpipeline.steps[1][1].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveJsonWindows(filenames=filenames_train, shift=[5, 6, 7], window=[50, 60, 70], x_transform=x_transform, y_train=y_train)\n",
    "SaveJsonWindows(filenames=filenames_val, shift=[5, 6, 7], window=[50, 60, 70], x_transform=x_test, y_train=y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
