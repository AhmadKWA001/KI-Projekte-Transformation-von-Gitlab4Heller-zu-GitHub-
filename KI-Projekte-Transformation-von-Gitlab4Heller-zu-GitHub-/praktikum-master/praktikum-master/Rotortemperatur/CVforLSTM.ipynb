{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV for different data settings for an LSTM to predict the magnet temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script loads a pipeline from a defined path and json files with different data settings.\n",
    "\n",
    "Then cross-validation is performed for each of these data settings.\n",
    "\n",
    "Currently the found models are **not** saved, only the parameters of the best models printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as ex\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from joblib import dump, load\n",
    " \n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, GRU, LSTM\n",
    "from keras.activations import relu, tanh, linear\n",
    "from keras.layers import Dropout\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, TerminateOnNaN, ModelCheckpoint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelinePath = \"X:\\\\RotorTempKI\\\\pipeline.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def usePipeline(pipelinePath, x_train, x_test):\n",
    "#     newpipeline = load(pipelinePath)\n",
    "#     newpipeline.steps[2][1].explained_variance_ratio_\n",
    "#     x_transform = newpipeline.fit_transform(x_train)\n",
    "#     x_validation = newpipeline.transform(x_test)\n",
    "\n",
    "#     return x_transform, x_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='val_loss', patience=100, verbose =1, mode = \"auto\")\n",
    "#csvLogger = CSVLogger('X:\\\\KI Praktikum\\\\csvLoggerCustomLoss.xlsx')\n",
    "stopNaN = TerminateOnNaN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(filepath, layers=[5, 5, 5], dropout=0, activation = \"relu\", input_shape = (1, 1), loss =\"mean_squared_error\"):\n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape))\n",
    "    \n",
    "    for i in range(len(layers)):\n",
    "        if i == len(layers)-1:\n",
    "            model.add(LSTM(layers[i], stateful = False, dropout=dropout, activation = activation, return_sequences=False))\n",
    "        else:\n",
    "            model.add(LSTM(layers[i], stateful = False, dropout=dropout, activation = activation, return_sequences=True))\n",
    "        #model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        #metrics=[ \"max_loss\"],\n",
    "        optimizer = \"Nadam\")\n",
    "    # return compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenJsontoArr(path):\n",
    "    file = open(path)\n",
    "    x_3d = json.load(file)\n",
    "    file.close()\n",
    "    x_3d = np.asarray(x_3d)\n",
    "    return x_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Custom loss function to reduce the absolute error of the individual sample as well as the \n",
    "maximum error\"\"\"\n",
    "def customLoss(y_true, y_pred):\n",
    "    weight = 1.5\n",
    "    difference = tf.abs(y_true - y_pred)\n",
    "    exponent = tf.exp(tf.multiply(weight, difference))\n",
    "    weighted_muls = tf.multiply(difference, exponent)\n",
    "    boltzmann_op = tf.reduce_sum(weighted_muls) / tf.reduce_sum(exponent)\n",
    "    loss = tf.add(boltzmann_op, tf.losses.mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [customLoss,          \n",
    "          tf.keras.losses.MeanSquaredError(),\n",
    "          tf.keras.losses.MeanAbsoluteError()]\n",
    "x_files_train = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonTrain\", \"*_x.json\"))\n",
    "y_files_train = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonTrain\", \"*_y.json\"))\n",
    "x_files_val = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonVal\", \"*_x.json\"))\n",
    "y_files_val = glob.glob(os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\8Tempsensors\\\\LSTMjsonVal\", \"*_y.json\"))\n",
    "windows = [50, 60, 70, 50, 60, 70, 50, 60, 70]\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_files_train)):\n",
    "    print(x_files_train[i])\n",
    "    x_cv = OpenJsontoArr(x_files_train[i])\n",
    "    x_test = OpenJsontoArr(x_files_val[i])\n",
    "    y_cv = OpenJsontoArr(y_files_train[i])\n",
    "    y_test = OpenJsontoArr(y_files_val[i])\n",
    "    y_cv = y_cv.flatten()\n",
    "    y_test = y_test.flatten()\n",
    "    \n",
    "    filepath = os.path.join(\"C:\\\\Users\\\\wch002\\\\Desktop\\\\RotorTempDRZ\\\\combined\\\\modelle\", \"model_\" + x_files_train[i][-19:-7] +\".h5\")\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    model = KerasRegressor(build_fn=get_lstm_model, filepath=filepath, verbose=0, layers=[5], dropout=0, activation = \"relu\", \n",
    "                            input_shape = (windows[i], 6), loss = losses)\n",
    "    #model.fit(x_cv, y_cv)\n",
    "    \n",
    "    grid = dict(layers = [[1], [5], [1, 2], [2, 2], [5, 2]],          #[[2], [5], [2, 2], [2, 5], [5, 2], [5, 5], [10, 5], [10, 10], [2, 2, 2]]       , [5, 5], [10, 5], [2, 2, 2]\n",
    "                dropout = [0],\n",
    "                activation = [\"relu\", \"tanh\", \"selu\", \"elu\"],\n",
    "                loss = losses)\n",
    "\n",
    "    searcher = RandomizedSearchCV(estimator=model, n_jobs=1, cv=3, param_distributions=grid, scoring='neg_mean_absolute_error', n_iter = 5)\n",
    "    searchResults = searcher.fit(x_cv, y_cv, batch_size = 500, epochs=500, callbacks = [earlyStop, stopNaN, checkpoint], use_multiprocessing = True)\n",
    "\n",
    "    bestScore = searchResults.best_score_\n",
    "    bestParams = searchResults.best_params_\n",
    "    bestModel = searchResults.best_estimator_\n",
    "    print(\"[INFO] best score is {:.2f} using {}\".format(bestScore, bestParams))\n",
    "    #bestModel.save(modelpaths[i])\n",
    "\n",
    "    best_pred_train = bestModel.predict(x_cv)\n",
    "    difference_train = y_cv - best_pred_train\n",
    "    error_avg_train = np.mean(abs(difference_train))\n",
    "    error_max_train = max(abs(difference_train))\n",
    "    print(\"Error over the training data:\")\n",
    "    print(\"max: \", error_max_train)\n",
    "    print(\"avg: \", error_avg_train)\n",
    "\n",
    "    best_pred_test = bestModel.predict(x_test)\n",
    "    difference_test = y_test - best_pred_test\n",
    "    error_avg_test = np.mean(abs(difference_test))\n",
    "    error_max_test = max(abs(difference_test))\n",
    "    print(\"Validation error:\")\n",
    "    print(\"max: \", error_max_test)\n",
    "    print(\"avg: \", error_avg_test)\n",
    "    \n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
