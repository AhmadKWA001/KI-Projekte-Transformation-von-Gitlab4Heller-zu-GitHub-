{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Libraries\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model, save_model\n",
    "import glob \n",
    "import  pandas as pd\n",
    "\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import os\n",
    "import sklearn as sk\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from keras.layers import Normalization\n",
    "from keras.layers import InputLayer,Subtract, Dot, Reshape, Input, Permute\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version= 'v0.0.13'\n",
    "workspace= \"G:\\\\Innovations@HELLER\\\\DN\\\\KI\\\\Zollern-FH-MillTrunMotor\\\\Datasets\\\\workspace\\\\data\\\\training\"\n",
    "assests_dir= 'G:\\\\Innovations@HELLER\\\\DN\\\\KI\\\\Zollern-FH-MillTrunMotor\\\\Datasets\\\\workspace\\\\assets\\\\New_Motor\\\\'+version+'\\\\'\n",
    "preprocessor_dir=assests_dir\n",
    "preprocessor_name='preprocessor.p'\n",
    "model_dir= assests_dir\n",
    "model_name= 'model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "pipeline= load(str(preprocessor_dir+preprocessor_name))\n",
    "print('preprocessor is loaded successfully')\n",
    "model= load_model(str(model_dir + model_name), compile= False)\n",
    "print('Model is loaded successfully')\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model as .keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(str(model_dir + 'model.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comp= pipeline.steps[1][1].components_.reshape((1,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comp.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert the pipeline to a keras code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using constant to pass to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not Working and it should be checked\n",
    "# input2_constant_ = tf.constant(pca_comp)\n",
    "# input1= Input(shape=(4,), name= \"Input_layer\")\n",
    "# #input2= Input(shape=(4,4), name=\"cov_matrix\", tensor= input2_constant)\n",
    "# normalized_data = Normalization(mean=pipeline.steps[0][1].mean_, variance=pipeline.steps[0][1].scale_ ** 2, name= \"Normalization_layer1\")(input1)\n",
    "# reshaped_normalized_data = normalized_data#Reshape((4, 1))(normalized_data)\n",
    "# input2_constant= input2_constant_#Permute((2, 1))(input2_constant_)\n",
    "# #reshaped_transposed_components = Reshape((4, 4))(input2_constant)\n",
    "# matrix_product = Dot(axes=(1,2) , name= \"Dot_Layer\")((reshaped_normalized_data, input2_constant))\n",
    "# normalized_pca= Normalization(name= \"Normalization_layer2\", mean= pipeline.steps[2][1].mean_, variance= pipeline.steps[2][1].scale_** 2)(matrix_product)\n",
    "# keras_preprocessor = Model(inputs=input1, outputs=normalized_pca, name= \"Preprocessor\",)\n",
    "# keras_preprocessor.compile()\n",
    "# test_input= np.asarray([[5,8,4,9]])\n",
    "# output_test= keras_preprocessor.evaluate(x= test_input)\n",
    "# print (keras_preprocessor.predict(test_input))\n",
    "# print(output_test)\n",
    "# print (\"Model Input: \",keras_preprocessor.input_shape, \"Model Output: \", keras_preprocessor.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_preprocessor.save(str(model_dir + 'preprocessor2.keras'))\n",
    "# loaded_model= load_model(str(model_dir + 'preprocessor2.keras'))\n",
    "# test_input= np.asarray([[5,8,4,9]])\n",
    "# loaded_model.predict([test_input, pca_comp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with cov-Matrix as second Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1= Input(shape=(4,), name= \"Input_layer\")\n",
    "input2= Input(shape=(4,4), name=\"cov_matrix\")\n",
    "normalized_data = Normalization(mean=pipeline.steps[0][1].mean_, variance=pipeline.steps[0][1].scale_ ** 2, name= \"Normalization_layer1\")(input1)\n",
    "#reshaped_transposed_components = Permute((2,1))(input2)\n",
    "matrix_product = Dot(axes= (1,2), name= \"Dot_Layer\")((normalized_data, input2))\n",
    "normalized_pca= Normalization(name= \"Normalization_layer2\", mean= pipeline.steps[2][1].mean_, variance= pipeline.steps[2][1].scale_** 2)(matrix_product)\n",
    "keras_preprocessor = Model(inputs=[input1, input2],outputs=normalized_pca, name= \"Preprocessor\")\n",
    "keras_preprocessor.compile()\n",
    "test_input= np.asarray([[5,8,4,9]])\n",
    "output_test= keras_preprocessor.evaluate(x= [test_input,pca_comp])\n",
    "print (keras_preprocessor.predict([test_input,pca_comp]))\n",
    "print(output_test)\n",
    "print (\"Model Input: \",keras_preprocessor.input_shape, \"Model Output: \", keras_preprocessor.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_preprocessor.save(str(model_dir + 'preprocessor.keras'))\n",
    "loaded_model= load_model(str(model_dir + 'preprocessor.keras'))\n",
    "test_input= np.asarray([[5,8,4,9]])\n",
    "loaded_model.predict([test_input, pca_comp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.transform(test_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
