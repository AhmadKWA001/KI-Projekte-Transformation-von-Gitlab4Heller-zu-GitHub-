{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/repaired_Files/Data_Verarbeitet/peak_removed_shifted/median/'\n",
    "# model_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/repaired_Files/Data_Verarbeitet/peak_removed_shifted/median/model.p'\n",
    "# preprocessor_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/repaired_Files/Data_Verarbeitet/peak_removed_shifted/median/preprocessor/preprocessor.p'\n",
    "# new_data_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed/'\n",
    "preprocessor_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed/AI_Model/preprocessor/preprocessor.p'\n",
    "model_dir= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed/AI_Model/model.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataSource(signal_input= None, input_columns: list = [], output_length: int=1, signal_output= None, window= 1 , shift= 1):\n",
    "    Signal_Length = signal_input.shape[0]\n",
    "    num_samples= int((Signal_Length - window + 1 ) / shift)\n",
    "    x = np.zeros(shape=(num_samples, window, signal_input.shape[1]))\n",
    "    y= np.zeros(shape=(num_samples, output_length, 1))#signal_output.shape[1]))\n",
    "    for i in range (num_samples):\n",
    "        x[i]= signal_input[i * shift : i * shift + window]\n",
    "        y[i]= signal_output[i * shift + window - 1 : i * shift + window - 1+ output_length]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM,Dense\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from joblib import load,dump\n",
    "## Extract Data source from all signals\n",
    "os.chdir(source_dir)\n",
    "selected_Columns= ['t_bett','t_motor','t_spindel', 'drhz']#['t_spindel', 'drhz']#'DRHZ', 'M8', 'M21','M121', 'smoothed_T_Spindel']\n",
    "results: np.ndarray= None\n",
    "targets: np.ndarray= None\n",
    "scaler= None\n",
    "for file in glob.glob('*.csv'):\n",
    "    if file == 'combined.csv':\n",
    "        continue\n",
    "    df= pd.read_csv(file)\n",
    "    signals= df[selected_Columns]\n",
    "    if scaler  is None:\n",
    "        try:\n",
    "            scaler= load(preprocessor_dir)\n",
    "            print('preprocessor is loaded successfully')\n",
    "        except FileNotFoundError as err:\n",
    "            scaler= MinMaxScaler(feature_range=(-1,1))\n",
    "            scaler= scaler.fit(signals)\n",
    "            dump(scaler, preprocessor_dir)\n",
    "            print('preprocessor is saved successfully')\n",
    "    signals= scaler.transform(signals)\n",
    "    signals= np.round(signals,2)\n",
    "    output= (df['z_tcp_ok']).round(6)# df['Z_TCP_OK']#\n",
    "    partitions, target= generateDataSource(signal_input= signals, input_columns= selected_Columns, output_length= 1,signal_output= output, window= 10, shift= 1)\n",
    "    if results is None:\n",
    "        results= partitions\n",
    "        targets= target\n",
    "    else:\n",
    "        results= np.concatenate((results, partitions), axis= 0)\n",
    "        targets= np.concatenate((targets, target), axis= 0)\n",
    "    print('input: ', results.shape, ' output:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df= pd.read_csv(source_dir+'data for testing and training/training.csv')\n",
    "testing_df= pd.read_csv(source_dir+'data for testing and training/test.csv')\n",
    "print (training_df.info)\n",
    "x_train= training_df['Predictors'].iloc(0)\n",
    "y_train= training_df['z_tcp_ok'].iloc(0)\n",
    "x_testing= testing_df['Predictors'].iloc(0)\n",
    "y_testing= testing_df['z_tcp_ok'].iloc(0)\n",
    "print (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Tolerance Lines\n",
    "import numpy as np\n",
    "tolerance= 0.005\n",
    "x_steps= np.linspace(-0.03, 0.06, 10)\n",
    "lowerline= x_steps - tolerance\n",
    "upperline= x_steps + tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Tolerance Lines\n",
    "import numpy as np\n",
    "tolerance= 0.01\n",
    "x_steps= np.linspace(-0.03, 0.06, 10)\n",
    "lowerline_actual= x_steps - tolerance\n",
    "upperline_actual= x_steps + tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Model\n",
    "from keras.models import load_model\n",
    "model=  Sequential()\n",
    "model= load_model(filepath= model_dir)\n",
    "print(model.summary())\n",
    "pred= model.predict(x_train)\n",
    "from keras.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "print ('mse= ',mean_squared_error(y_train,pred), ' mae= ', mean_absolute_error(y_train,pred), ' mape= ', mean_absolute_percentage_error(y_train,pred))\n",
    "fig, ax= plt.subplots(figsize=(15,15))\n",
    "\n",
    "plt.title('Results of RandomForest Algorithm')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.grid()\n",
    "plt.plot(x_steps, upperline, label= 'Upper Bound', color='green')\n",
    "plt.scatter(targets,pred, label= 'predictions')\n",
    "plt.plot(x_steps, lowerline, label= 'lower Bound', color='green')\n",
    "plt.plot(x_steps, x_steps, label= 'Optimal line')\n",
    "plt.plot(x_steps, lowerline_actual, label= 'Actual lower Bound', color='red')\n",
    "plt.plot(x_steps, upperline_actual, label= 'Actual Upper Bound', color='red')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "98516c4905fb8467ece250085a11958ff6a81ba629b2fa3655ee37336959c16d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
