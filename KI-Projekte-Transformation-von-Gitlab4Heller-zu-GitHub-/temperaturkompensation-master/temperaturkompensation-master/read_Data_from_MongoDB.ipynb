{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate local predictions of data located in edgebox and compare them with the previously online created results (Just generation. Not simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Libraries\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from keras.models import Model, load_model\n",
    "import glob \n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DB Config\n",
    "host= \"Devedgev32\"\n",
    "port=27017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to remove t_bett from t_spindel and t_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to smooth a signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a data set, where each data point is a window of n steps (look window feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the time period to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start= datetime.strptime(\"2022-09-20T22:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")# Trocken iso\n",
    "#end= datetime.strptime (\"2022-09-21T08:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "#start= datetime.strptime(\"2023-02-02T10:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")# Trocken iso\n",
    "#end= datetime.strptime (\"2023-02-02T18:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "# start= datetime.strptime(\"2023-01-31T17:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") #Messtaster mit Fräsversuch\n",
    "# end= datetime.strptime (\"2023-01-31T23:59:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "# start= datetime.strptime(\"2023-02-23T18:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") #Messtaster mit Fräsversuch\n",
    "# end= datetime.strptime (\"2023-02-24T00:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "start= datetime.strptime(\"2023-04-16T00:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "end= datetime.strptime (\"2023-04-19T00:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the mongo_DB database and apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host= host, port=port)\n",
    "db = client.h4ai\n",
    "event_list = db.modelLogs.find({ \"date\" : { '$gte' : start, '$lt' : end} }).sort('date', 1)\n",
    "signals= None#pd.DataFrame({})\n",
    "signals= pd.DataFrame({})\n",
    "List=[]\n",
    "x=0\n",
    "i=0\n",
    "dicss={  \"T_KWAV1\": \"/NCK/State/adbr[2400]\",\n",
    "      \"T_KWAR1_MS\": \"/NCK/State/adbr[2404]\",\n",
    "      \"T_KWR_MS\": \"/NCK/State/adbr[2408]\",\n",
    "      \"V_KW_MS\": \"/NCK/State/adbr[2412]\",\n",
    "      \"V_KWAV1\": \"/NCK/State/adbr[2416]\",\n",
    "      \"V_KWAV2\": \"/NCK/State/adbr[2480]\",\n",
    "      \"T_KSM1\": \"/NCK/State/adbr[2420]\",\n",
    "      \"T_SCHLITTEN_Y\": \"/NCK/State/adbr[2424]\",\n",
    "      \"T_SPI_MB1\": \"/NCK/State/adbr[2428]\",\n",
    "      \"T_SPI_MB2\": \"/NCK/State/adbr[2436]\",\n",
    "      \"T_RAUM\": \"/NCK/State/adbr[2440]\",\n",
    "      \"T_BETT_X\": \"/NCK/State/adbr[2444]\",\n",
    "      \"T_STAE_Y\": \"/NCK/State/adbr[2448]\",\n",
    "      \"T_BETT_Z\": \"/NCK/State/adbr[2452]\",\n",
    "      \"T_Spindel\": \"/NCK/State/adbr[2456]\",\n",
    "      \"ActSpeed_S\": \"/Channel/Spindle/actSpeed[u1,1]\",\n",
    "      \"Power_S\": \"/Channel/MachineAxis/aaPower[u1,8]\",\n",
    "      \"Torque_S\": \"/Channel/MachineAxis/aaTorque[u1,8]\",\n",
    "      \"Current_S\": \"/Channel/MachineAxis/aaCurr[u1,8]\",\n",
    "      \"T_Motor_S\": \"/DriveVsa/Drive/r0035[u8]\"}\n",
    "Names=[  \"T_BETT_X\",\n",
    "      \"T_Spindel\",\n",
    "      \"T_Motor_S\"]\n",
    "[Names.append(i) for i in dicss.keys()]\n",
    "last_prediction= -500\n",
    "prev_record_time= None\n",
    "### Go through events in DB\n",
    "# signals=None\n",
    "for event in event_list:\n",
    "    i+=1\n",
    "    record_list= event['content']\n",
    "    keys= None\n",
    "    ### Go through records in each event\n",
    "    for record in record_list:\n",
    "        if record['date']< start or record['date'] > end:\n",
    "            continue\n",
    "        \n",
    "       \n",
    "        keys= record['raw_data'].keys()\n",
    "        record['raw_data']['date']=record['date'] + timedelta(hours= +2)\n",
    "        for item in keys:\n",
    "            record['raw_data'][item]= [record['raw_data'][item]]\n",
    "     \n",
    "        lf_signal_point= pd.DataFrame(record['raw_data'])\n",
    "        if signals is None:\n",
    "            signals=lf_signal_point.copy()\n",
    "        else :\n",
    "            # pd.concat(signalslf_signal_point.copy(),)\n",
    "                signals=signals.append(lf_signal_point,ignore_index=True)\n",
    "\n",
    "        if len(List)==0:\n",
    "            List.append(lf_signal_point.copy())\n",
    "        else:\n",
    "            List.append(lf_signal_point)#,ignore_index= True)#signals= \n",
    "signals=signals.append(List,ignore_index=True)\n",
    "signals.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals=pd.read_csv('C:\\\\Users\\\\kwa001\\\\Downloads\\\\Flow_creator\\\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for col in signals.columns:\n",
    "    if re.search(r\"^[T_]\",col):\n",
    "        signals.loc[:,col]=signals.loc[:,col].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.loc[: ,'V_KW_MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (T_Rück - T_Vor) * V [l/min] * 1,16 *60/1000 => Kühlleistung in kW\n",
    "dff=(signals.loc[:,'T_KWR_MS'] - signals.loc[:,'T_KWAV1']) *signals.loc[: ,'V_KW_MS']*(1000/60) * (1.16) *(60/1000)\n",
    "signals['Kühlleistung']=dff\n",
    "\n",
    "# signals.insert(0,'Kühlleistung',dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.io as pio\n",
    "\n",
    "columns=['T_BETT_X', 'T_Spindel', 'T_Motor_S', 'T_BETT_Z', 'Torque_S'#]#,\n",
    "       ,'ActSpeed_S', 'T_STAE_Y', 'Power_S', 'T_KWR_MS', 'T_SCHLITTEN_Y'#]#,\n",
    "       ,'T_RAUM', 'V_KW_MS', 'Current_S', 'T_KWAR1_MS', 'T_KWAV1', 'V_KWAV1']\n",
    "    #    'T_KSM1', 'V_KWAV2', 'T_SPI_MB1', 'T_SPI_MB2', 'T_Motor_Z',\n",
    "    #    'T_Motor_X', 'Power_B', 'Power_Y', 'Torque_Z', 'Current_A', 'T_Motor_A',\n",
    "    #    'Torque_Y', 'Current_B', 'Power_A', 'Power_X', 'T_Motor_B', 'T_Motor_Y',\n",
    "    #    'Power_Z', 'Torque_A', 'Current_X', 'Current_Z', 'Torque_B', 'Torque_X',\n",
    "    #    'Current_Y']\n",
    "columnss=['T_BETT_X°', 'T_Spindel°', 'T_Motor_S°', 'T_BETT_Z°', 'Torque_S'#]#,\n",
    "       ,'ActSpeed_S(R\\M)', 'T_STAE_Y°', 'Power_S', 'T_KWR_MS°', 'T_SCHLITTEN_Y°','T_RAUM°', 'V_KW_MS', 'Current_S', 'T_KWAR1_MS°', 'T_KWAV1°', 'V_KWAV1','Kühlleistung']#,\n",
    "\n",
    "columns1=['T_BETT_X(°C)', 'T_Spindel(°C)', 'T_Motor_S(°C)', 'T_BETT_Z(°C)', 'Torque_S(NM)'#]#,\n",
    "       ,'ActSpeed_S(NM)', 'T_STAE_Y(°C)', 'Power_S(KW)', 'T_KWR_MS(°C)', 'T_SCHLITTEN_Y(°C)','T_RAUM(°C)', 'V_KW_MS(L/m)', 'Current_S', 'T_KWAR1_MS(°C)', 'T_KWAV1(°C)', 'V_KWAV1(L/m)','Kühlleistung(KW)']\n",
    "\n",
    "scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "\n",
    "fig= make_subplots(rows=len(columns),cols=1,shared_xaxes= True, print_grid= True, vertical_spacing=0.02,subplot_titles=columnss)\n",
    "ii=1\n",
    "for i in range(len(columns)):\n",
    "\n",
    "    #fig= make_subplots(rows=9,cols=1,shared_xaxes= True, print_grid= True, vertical_spacing=0.02,subplot_titles=['t_bett',' Hals','t_spindel','t_schlitten','Schlitten_copm','Gesamte_comp','Fehler_comp',' welle','Prediction_30S'])\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=signals['date'], y=signals[columns[i]], name=columnss[i], mode= scatter_mode), row= ii, col= 1)\n",
    "    fig.update_yaxes(title_text= columns1[i], row= ii, col= 1)\n",
    "    ii=ii+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#,range=[0,len(df_list2[0])]\n",
    "#fig.update_xaxes( title=\"seconds\" )#range=[0,len(df_list2[0])] \n",
    "\n",
    "\n",
    "#pio.write_image(fig,'C:\\\\Users\\\\KWA001\\\\Downloads\\\\Neuer Ordner\\\\'+str(i)+'.png','png')\n",
    "#fig.write_image('C:\\\\Users\\\\KWA001\\\\Downloads\\\\Neuer Ordner\\\\'+str(i)+'.png')\n",
    "\n",
    "fig.update_layout(height=3000, width=1200, title_text='Machine HF5500' )#'Hals_comp_VS_Hals_PT!_Glied _Versuch{}'.format(j)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.to_csv('G:\\\\Innovations@HELLER\\\\DN\\KI\\\\flow_creator\\\\data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f5991dfbe9abcdaf49e07ee2ab45c9a35d68345edbf6bea87574bfe29d859a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
