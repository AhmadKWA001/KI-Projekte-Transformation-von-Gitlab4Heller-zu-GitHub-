{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Libraries\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from keras.models import Model, load_model\n",
    "import glob \n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DB Config\n",
    "host= \"DevEdgeV32\"\n",
    "port=27017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set parameters\n",
    "preprocessor_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/preprocessor/'\n",
    "preprocessor_name='preprocessor.p'\n",
    "model_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/model/'\n",
    "model_name= 'model.h5'\n",
    "selected_Columns=  ['t_bett','t_motor', 't_spindle','M8', 'M121', 'M127', 'M7']# So must be the input of the model\n",
    "output_variable= 'welle_z'\n",
    "prediction_variable= 'prediction'\n",
    "window=10\n",
    "shift= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to remove t_bett from t_spindel and t_motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_t_bett(data: np.ndarray):\n",
    "    result= data[:, 1:]\n",
    "    result[:,0]= result[:,0] - data[:,0]\n",
    "    result[:,1]= result[:,1] - data[:,0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to apply rounding on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(signals: np.ndarray):\n",
    "    return np.round(signals,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to smooth a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_peeks(dlf: pd.DataFrame, feature: str,window):\n",
    "    df= dlf.copy()\n",
    "    new_Feature_name= 'smoothed_' + feature\n",
    "    df[new_Feature_name]= df[feature].rolling(window).mean().to_list()\n",
    "    shape= df.shape\n",
    "    offset= int(np.round(window/2))\n",
    "    for i in range(df.shape[0] - offset):\n",
    "        df.loc[i, new_Feature_name]= df.iloc[i + offset][new_Feature_name]\n",
    "    df= df[df[new_Feature_name] == df[new_Feature_name]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a data set, where each data point is a window of n steps (look window feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataSource(signal_input= None, output_length: int=1, signal_output= None, window= 1 , shift= 1):\n",
    "    Signal_Length = signal_input.shape[0]\n",
    "    num_samples= int((Signal_Length - window +1 ) / shift)\n",
    "    x = np.zeros(shape=(num_samples, window, signal_input.shape[1]))\n",
    "    y= np.zeros(shape=(num_samples, output_length, 1))\n",
    "    for i in range (num_samples):\n",
    "        x[i]= signal_input[i * shift : i * shift + window]\n",
    "        if signal_output is not None:\n",
    "            y[i]= signal_output[i * shift + window - 1 : i * shift + window - 1+ output_length]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the time period to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start= datetime.strptime(\"2022-08-30T15:26:06.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") \n",
    "start= datetime.strptime(\"2022-09-24T18:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "end= datetime.strptime(\"2022-09-26T05:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the mongo_DB database and apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read raws and preprocessing data\n",
    "client = MongoClient(host= host, port=port)\n",
    "db = client.h4ai\n",
    "event_list = db.modelLogs.find({ \"date\" : { '$gte' : start, '$lt' : end} }).sort('date', 1)\n",
    "signals= None\n",
    "i=0\n",
    "last_prediction= -500\n",
    "### Go through events in DB\n",
    "for event in event_list:\n",
    "    i+=1\n",
    "    record_list= event['content']\n",
    "    keys= None\n",
    "    ### Go through records in each event\n",
    "    for record in record_list:\n",
    "        if record['date']< start or record['date'] > end:\n",
    "            continue\n",
    "        if 'given2model' not in record:\n",
    "            if record[prediction_variable] == last_prediction:\n",
    "                record['given2model']= False\n",
    "            else:\n",
    "                last_prediction= record[prediction_variable]\n",
    "                record['given2model']= True\n",
    "        keys= record['raw_data'].keys()\n",
    "        for item in keys:\n",
    "            record['raw_data'][item]= [record['raw_data'][item]]\n",
    "        #print ('before',record)\n",
    "        record['raw_data']['date']=[record['date'] + timedelta(hours= +2)]\n",
    "        record['raw_data'][output_variable]=[record[output_variable]]\n",
    "        record['raw_data'][prediction_variable]=[record[prediction_variable]]\n",
    "        record['raw_data']['DRZ2'][0]= float(record['raw_data']['DRZ2'][0])\n",
    "        # record['raw_data']['M8']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['M121']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['M127']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['M7']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['t_spindle'][0]= np.round(record['raw_data']['t_spindle'][0] - record['raw_data']['t_bett'][0], decimals=2)\n",
    "        # record['raw_data']['t_motor']= np.round(float(record['raw_data']['t_motor'][0]) - record['raw_data']['t_bett'][0], decimals= 2)\n",
    "        record['raw_data']['t_spindle'][0]= np.round(record['raw_data']['t_spindle'][0], decimals=2)\n",
    "        record['raw_data']['t_motor']= np.round(float(record['raw_data']['t_motor'][0]), decimals= 2)\n",
    "        #####Add preprocessed Data##########\n",
    "        record['raw_data']['0']= record['preprocessed_data'][0]\n",
    "        record['raw_data']['1']= record['preprocessed_data'][1]\n",
    "        record['raw_data']['2']= record['preprocessed_data'][2]\n",
    "        record['raw_data']['3']= record['preprocessed_data'][3]\n",
    "        record['raw_data']['4']= record['preprocessed_data'][4]\n",
    "        record['raw_data']['5']= record['preprocessed_data'][5]\n",
    "        ####################################\n",
    "        record['raw_data']['given2model']= record['given2model']\n",
    "        #print ('After ',record)\n",
    "        lf_signal_point= pd.DataFrame(record['raw_data'])\n",
    "        if signals is None:\n",
    "            signals= lf_signal_point\n",
    "        else:\n",
    "            signals= signals.append(lf_signal_point,ignore_index= True)\n",
    "signals['t_motor']= signals['t_motor'].apply(np.float32)\n",
    "# signals['prediction_abs_error']= signals[prediction_variable] -signals[output_variable]\n",
    "# signals['prediction_abs_error']= 1000 * signals['prediction_abs_error'].abs()\n",
    "signals.reset_index(inplace= True)\n",
    "####To save as csv_File####\n",
    "# \n",
    "# #signals = remove_peeks(signals, output_variable, 4)\n",
    "output=  signals[output_variable]\n",
    "machine_prediction= signals[prediction_variable]\n",
    "rough_signals= signals[selected_Columns].to_numpy()\n",
    "print(rough_signals.shape)\n",
    "#signals.rename(columns={'t_spindle': 't_spindel', 'DRZ': 'drhz'}, inplace= True)\n",
    "print (signals.head(3))\n",
    "print (signals.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through the records in database an correct the delay of the welle_z, where a new value of 'welle_z' is available when 'given2model' is true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signals['welle_z']= signals['welle_z'].shift(-1)\n",
    "length= len(signals)\n",
    "start= -1\n",
    "end= -1\n",
    "phases=[]\n",
    "for index, row in signals.iterrows():\n",
    "    if start<0:\n",
    "        start= index\n",
    "        continue\n",
    "    if row['given2model'] or index == length - 1:\n",
    "        end= index-1\n",
    "        new_phase= (start, end)\n",
    "        phases.append(new_phase)\n",
    "        start= index\n",
    "        print(new_phase)\n",
    "for phase in phases:\n",
    "    start_idx= phase[0]\n",
    "    end_idx= phase[1]\n",
    "    signals['welle_z'][start_idx: end_idx + 1]= signals['welle_z'][end_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.to_csv('corrected_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the prediction results and created before during the execution of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "selected_Columns= ['t_bett','t_motor', 't_spindle' ,'M8', 'M121', 'M127', 'M7', prediction_variable]#'0','1','2','3','4','5'\n",
    "y_axis_names= selected_Columns\n",
    "#print(preds)\n",
    "prediction_error= 1000*(signals[output_variable] - signals[prediction_variable])\n",
    "fig= make_subplots(rows=len(selected_Columns)+1,cols=1,shared_xaxes= True, print_grid= True, subplot_titles= selected_Columns, vertical_spacing=0.02)\n",
    "\n",
    "for i in range(len(selected_Columns)):\n",
    "    fig.add_trace(go.Scatter(x= signals['date'], y= signals[selected_Columns[i]], name=selected_Columns[i], mode= scatter_mode), row= i+1, col= 1)\n",
    "    fig.update_yaxes(title_text= y_axis_names[i], row= i+1, col= 1)\n",
    "##Draw the prediciton and the real values of displacement on Welle\n",
    "fig.add_trace(go.Scatter(x= signals['date'],y= signals[output_variable], name=output_variable, mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.update_yaxes(title_text= output_variable, row= len(selected_Columns), col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y=   prediction_error, name=' Rest Fehler Micro-Meter', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "## Draw the tolerence +-5\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(prediction_error,5), name='+5 Obere Grenze', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(prediction_error,-5), name='- 5 Obere Grenze', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.update_layout(height=1200, width=1400, title_text= 'Prediction Results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "98516c4905fb8467ece250085a11958ff6a81ba629b2fa3655ee37336959c16d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
