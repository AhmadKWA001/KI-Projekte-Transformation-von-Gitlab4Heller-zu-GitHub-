{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate local predictions of data located in edgebox and compare them with the previously online created results (Just generation. Not simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Libraries\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from keras.models import Model, load_model\n",
    "import glob \n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DB Config\n",
    "host= \"DevEdgeV32\"\n",
    "port=27017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set parameters\n",
    "preprocessor_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/preprocessor/'\n",
    "preprocessor_name='preprocessor.p'\n",
    "model_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/model/'\n",
    "model_name= 'model.h5'\n",
    "selected_Columns=  ['t_bett', 't_spindle','t_motor', 'M8','M121', 'M127', 'M7']# So must be the input of the model\n",
    "output_variable= 'welle_z'\n",
    "prediction_variable= 'prediction'\n",
    "window = 60\n",
    "shift = 6\n",
    "sampling_rate= 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funtion to remove t_bett from t_spindel and t_motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_t_bett___(data: np.ndarray):\n",
    "    result= data[:, 1:]\n",
    "    result[:,0]= result[:,0] - data[:,0]\n",
    "    result[:,1]= result[:,1] - data[:,0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(signals: np.ndarray):\n",
    "    ##rounding t_motor to nearest integer\n",
    "    signals[:,1]= np.round(signals[:,1])\n",
    "    signals= np.round(signals, 2)\n",
    "    return signals\n",
    "\n",
    "def rounding2(signals: np.ndarray):\n",
    "    return np.round(signals, 5)\n",
    "\n",
    "\n",
    "def remove_t_bett(data: np.ndarray):\n",
    "    result = data[:, 1:]\n",
    "    result[:, 0] = result[:, 0] - data[:, 0]\n",
    "    result[:, 1] = result[:, 1] - data[:, 0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to smooth a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_peeks(dlf: pd.DataFrame, feature: str,window):\n",
    "    df= dlf.copy()\n",
    "    new_Feature_name= 'smoothed_' + feature\n",
    "    df[new_Feature_name]= df[feature].rolling(window).mean().to_list()\n",
    "    shape= df.shape\n",
    "    offset= int(np.round(window/2))\n",
    "    for i in range(df.shape[0] - offset):\n",
    "        df.loc[i, new_Feature_name]= df.iloc[i + offset][new_Feature_name]\n",
    "    df= df[df[new_Feature_name] == df[new_Feature_name]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a data set, where each data point is a window of n steps (look window feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### window  represents time period by each entry in the buffer\n",
    "### Shift represents the jump from value to next one in the buffer\n",
    "### sampling rate \n",
    "def generateDataSource(signal_input=None, input_columns: list = [], output_length: int = 1, signal_output=None, window=1, shift=1, sample_rate=1):\n",
    "    subsequence_len= (window -1) *shift + 1\n",
    "    Signal_Length = signal_input.shape[0]\n",
    "    #num_samples = int((Signal_Length - (window-1) * shift))\n",
    "    #num_samples = int((Signal_Length - window + 1) / shift)\n",
    "    num_samples = 1 + int((Signal_Length - subsequence_len) / sample_rate)\n",
    "    x = np.zeros(shape=(num_samples, window, signal_input.shape[1]))\n",
    "    y = np.zeros(shape=(num_samples, output_length, 1))\n",
    "    for i in range(num_samples):\n",
    "        x[i] = np.asarray([signal_input[i*sample_rate + j * shift] for j in range(0,window)])\n",
    "        y[i] = signal_output[i*sample_rate + (window-1) * shift :i*sample_rate+ (window-1) * shift + output_length]\n",
    "#        print('x[{}]= {}'.format(i, x[i]))\n",
    "#        print('y[{}]= {}'.format(i, y[i]))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the time period to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start= datetime.strptime(\"2022-09-20T22:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")# Trocken iso\n",
    "#end= datetime.strptime (\"2022-09-21T08:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "#start= datetime.strptime(\"2023-02-02T10:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")# Trocken iso\n",
    "#end= datetime.strptime (\"2023-02-02T18:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "# start= datetime.strptime(\"2023-01-31T17:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") #Messtaster mit Fräsversuch\n",
    "# end= datetime.strptime (\"2023-01-31T23:59:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "# start= datetime.strptime(\"2023-02-23T18:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") #Messtaster mit Fräsversuch\n",
    "# end= datetime.strptime (\"2023-02-24T00:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "start= datetime.strptime(\"2023-03-01T11:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "end= datetime.strptime (\"2023-03-01T17:59:59.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the mongo_DB database and apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read raws and preprocessing data\n",
    "client = MongoClient(host= host, port=port)\n",
    "db = client.h4ai\n",
    "event_list = db.modelLogs.find({ \"date\" : { '$gte' : start, '$lt' : end} }).sort('date', 1)\n",
    "signals= None\n",
    "i=0\n",
    "last_prediction= -500\n",
    "prev_record_time= None\n",
    "### Go through events in DB\n",
    "for event in event_list:\n",
    "    i+=1\n",
    "    record_list= event['content']\n",
    "    keys= None\n",
    "    ### Go through records in each event\n",
    "    for record in record_list:\n",
    "        if record['date']< start or record['date'] > end:\n",
    "            continue\n",
    "        if prev_record_time is not None and (record['date']  - prev_record_time).total_seconds() < 5:\n",
    "            print('Escaped!')\n",
    "            continue\n",
    "        else:\n",
    "            prev_record_time= record['date']\n",
    "        if 'given2model' not in record:\n",
    "            if record[prediction_variable] == last_prediction:\n",
    "                record['given2model']= False\n",
    "            else:\n",
    "                last_prediction= record[prediction_variable]\n",
    "                record['given2model']= True\n",
    "        keys= record['raw_data'].keys()\n",
    "        for item in keys:\n",
    "            record['raw_data'][item]= [record['raw_data'][item]]\n",
    "        #print ('before',record)\n",
    "        record['raw_data']['date']=[record['date'] + timedelta(hours= +2)]\n",
    "        record['raw_data'][output_variable]=[record[output_variable]]\n",
    "        record['raw_data'][prediction_variable]=[record[prediction_variable]]\n",
    "        #record['raw_data']['DRZ2']= [float(record['DRZ2'])]\n",
    "        # record['raw_data']['M8']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['M121']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['M127']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['M7']= 0#(0 if record['raw_data']['DRZ'][0]<300 else 1)\n",
    "        # record['raw_data']['t_spindle'][0]= np.round(record['raw_data']['t_spindle'][0] - record['raw_data']['t_bett'][0], decimals=2)\n",
    "        # record['raw_data']['t_motor']= np.round(float(record['raw_data']['t_motor'][0]) - record['raw_data']['t_bett'][0], decimals= 2)\n",
    "        record['raw_data']['t_spindle'][0]= np.round(record['raw_data']['t_spindle'][0], decimals=2)\n",
    "        record['raw_data']['t_motor']= np.round(float(record['raw_data']['t_motor'][0]), decimals= 2)\n",
    "        #####Add preprocessed Data##########\n",
    "        record['raw_data']['0']= record['preprocessed_data'][0]\n",
    "        record['raw_data']['1']= record['preprocessed_data'][1]\n",
    "        record['raw_data']['2']= record['preprocessed_data'][2]\n",
    "        record['raw_data']['3']= record['preprocessed_data'][3]\n",
    "        record['raw_data']['4']= record['preprocessed_data'][4]\n",
    "        record['raw_data']['5']= record['preprocessed_data'][5]\n",
    "        ####################################\n",
    "        record['raw_data']['given2model']= record['given2model']\n",
    "        #print ('After ',record)\n",
    "        lf_signal_point= pd.DataFrame(record['raw_data'])\n",
    "        if signals is None:\n",
    "            signals= lf_signal_point\n",
    "        else:\n",
    "            signals= signals.append(lf_signal_point,ignore_index= True)\n",
    "signals['t_motor']= signals['t_motor'].apply(np.float32)\n",
    "# signals['prediction_abs_error']= signals[prediction_variable] -signals[output_variable]\n",
    "# signals['prediction_abs_error']= 1000 * signals['prediction_abs_error'].abs()\n",
    "signals.reset_index(inplace= True)\n",
    "####smoothing singals####\n",
    "#signals= smoothing_data(signals,24)\n",
    "# #signals = remove_peeks(signals, output_variable, 4)\n",
    "####Apply enterpolation###\n",
    "#output_variable= str(output_variable+'_smoothed')\n",
    "upsampled_variable= output_variable#str('interpolated_'+output_variable)\n",
    "signals[upsampled_variable]= signals[output_variable]\n",
    "current_welle_z= 1000000\n",
    "for index, row in signals.iterrows():\n",
    "    if row[upsampled_variable]!= current_welle_z: ### A New value is available\n",
    "        current_welle_z= row[upsampled_variable]\n",
    "    else:\n",
    "        signals.at[index,upsampled_variable]= np.NaN\n",
    "signals[upsampled_variable].interpolate(method='linear', order=3, axis= 0,inplace= True)\n",
    "output=  signals[output_variable]\n",
    "machine_prediction= signals[prediction_variable]\n",
    "rough_signals= signals[selected_Columns].to_numpy()\n",
    "print(rough_signals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input signal shape=', rough_signals.shape, 'output shape= ', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate prediction based on the transformed data in DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Model and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "pipeline= load(str(preprocessor_dir+preprocessor_name))\n",
    "print(pipeline)\n",
    "#pipeline.verbose()\n",
    "print('preprocessor is loaded successfully')\n",
    "model= load_model(str(model_dir + model_name), compile= False)\n",
    "print('Model is loaded successfully')\n",
    "print ('Model Input= ', model.input_shape,'Model output= ', model.output_shape)\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessor on the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_signals= pipeline.transform(rough_signals)\n",
    "transformed_signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_signals_windowed, output= generateDataSource(signal_input=transformed_signals, signal_output=output, window= window, shift= shift, sample_rate= sampling_rate)\n",
    "print('transformed_signals_windowed: ', transformed_signals_windowed.shape, 'label: ', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprcessed_signals= transformed_signals_windowed#transformed_signals#signals[['0','1','2','3','4','5']].to_numpy()\n",
    "results= preprcessed_signals\n",
    "targets= output\n",
    "output= np.reshape(targets,-1)\n",
    "print('input: ', results.shape, ' output:', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds= model.predict(results)/1000\n",
    "preds= np.reshape(preds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_shifted= preds#np.concatenate((np.zeros( shape= (window-1,)), preds))\n",
    "prediction_error= np.abs(targets- preds_shifted)\n",
    "min_error= np.min(prediction_error)\n",
    "max_error= np.max(prediction_error)\n",
    "mean_error= np.mean(prediction_error)\n",
    "prediction_error= targets- preds_shifted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shift=  (window ) * (shift) #abs(rough_signals.shape[0] - results.shape[0])\n",
    "print(input_shift)\n",
    "visualization_df= signals.iloc[input_shift:]\n",
    "pred_doubled= np.zeros(shape=(len(visualization_df),))\n",
    "for i in range(0, preds_shifted.shape[0]):\n",
    "    pred_doubled[i*sampling_rate: i*sampling_rate + sampling_rate ]= preds_shifted[i]\n",
    "visualization_df['upsampled_predictions']= pred_doubled\n",
    "visualization_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels + prediction +Error and the upper and lower limit in one block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "# # selected_Columns= ['t_bett','t_motor', 't_spindle' ,'M8', 'M121', 'M127', 'M7', prediction_variable, output_variable, 'db_prediction_abs_error']\n",
    "# # y_axis_names= selected_Columns\n",
    "# #print(preds)\n",
    "# fig= make_subplots(rows=1,cols=1,shared_xaxes= True, print_grid= True, vertical_spacing=0.02)\n",
    "# ##Verlagerung\n",
    "# fig.add_trace(go.Scatter(x= signals['date'], y= 1000 * signals[output_variable], name='Gemessene Verlagerung (Welle)', mode= scatter_mode), row= 1, col= 1)\n",
    "# fig.add_trace(go.Scatter(x= signals['date'], y= 1000 * signals[prediction_variable], name='KI-basierte Verlagerung (Welle)', mode= scatter_mode), row= 1, col= 1)\n",
    "\n",
    "# ##Restfehler\n",
    "# fig.add_trace(go.Scatter(x= signals['date'], y= 1000 * signals[output_variable] - 1000 * signals[prediction_variable], name=' Restfehler', mode= scatter_mode),  row= 1 , col= 1)\n",
    "# ## Draw the tolerence +-5\n",
    "# fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(signals[output_variable],5), name='+5 Obere Grenze', mode= scatter_mode),  row= 1 , col= 1)\n",
    "# fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(signals[output_variable],-5), name='- 5 Obere Grenze', mode= scatter_mode),  row= 1 , col= 1)\n",
    "# fig.update_yaxes(title_text= 'Verlagerung Micro-Meter', row= 1, col= 1)\n",
    "# fig.update_layout(height=1200, width=1400, title_text= 'M57002 Machine Data, Versuch am 2023-01-11T20:00:00 ISO 230-3 Trocken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparasion between two sources:\n",
    "from turtle import color\n",
    "\n",
    "scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "local_model_predictions= 'upsampled_predictions'\n",
    "#visualization_df[old_model_predictions]=visualization_df[prediction_variable]\n",
    "selected_Columns= ['t_bett','t_motor', 't_spindle' ,  prediction_variable]\n",
    "#selected_Columns= ['t_bett','t_motor', 't_spindle','DRZ','DRZ2', prediction_variable]\n",
    "#selected_Columns.append('prediction_abs_error')\n",
    "print (selected_Columns)\n",
    "y_axis_names= selected_Columns\n",
    "#print(preds)\n",
    "fig= make_subplots(rows=len(selected_Columns)+1,cols=1,shared_xaxes= True, print_grid= True, subplot_titles= selected_Columns, vertical_spacing=0.02)\n",
    "\n",
    "for i in range(len(selected_Columns)):\n",
    "    fig.add_trace(go.Scatter(x= visualization_df['date'], y= visualization_df[selected_Columns[i]], name=selected_Columns[i], mode= scatter_mode), row= i+1, col= 1)\n",
    "    fig.update_yaxes(title_text= y_axis_names[i], row= i+1, col= 1)\n",
    "##Draw the prediciton and the real values of displacement on Welle\n",
    "fig.add_trace(go.Scatter(x= visualization_df['date'],y= visualization_df[local_model_predictions], name=local_model_predictions, mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.add_trace(go.Scatter(x= visualization_df['date'],y= visualization_df[output_variable], name=output_variable, mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.update_yaxes(title_text= output_variable, row= len(selected_Columns), col= 1)\n",
    "fig.add_trace(go.Scatter(x= visualization_df['date'], y=   1000*(visualization_df[output_variable] - visualization_df[prediction_variable]), name='Mchine Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= visualization_df['date'], y=   1000*(visualization_df[output_variable] - visualization_df[local_model_predictions]), name='local Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "## Draw the tolerence +-5\n",
    "fig.add_trace(go.Scatter(x= visualization_df['date'], y= np.full_like(visualization_df[output_variable],5), name='+5 Max Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= visualization_df['date'], y= np.full_like(visualization_df[output_variable],-5), name='-5 Min Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "\n",
    "#fig.add_trace(go.Scatter(x= signals['date'], y=   1000*( np.abs(signals[output_variable] - signals[prediction_variable])), name='Old Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.update_yaxes(title_text= 'Error (Micro-meter)', row= len(selected_Columns)+1, col= 1)\n",
    "fig.update_layout(height=1200, width=1400, title_text= 'Prediction Results')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "98516c4905fb8467ece250085a11958ff6a81ba629b2fa3655ee37336959c16d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
