{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb as ddb\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir= \"G:\\\\Innovations@HELLER\\\\DN\\\\KI\\\\Temperaturkompensation\\\\2021_Spindelwachstumskompensation_KI_HSU_SC63\\\\Messungen DC100 H5000 M57002\\\\row_files\\\\for_combination\\\\\"\n",
    "#dir=\"C:/#D von 65456/Neuer Ordner/\"\n",
    "temp_file=''\n",
    "log_file= '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measures_date_format= \"%Y-%m-%d %H:%M:%S\" #\"%Y.%m.%d %H:%M:%S\"# \"2022-02-25 15:30:00\"\n",
    "df_log_date_format= \"%Y/%m/%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateparse (time_str):    \n",
    "    return pd.to_datetime(time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_special_numbers(df: pd.DataFrame, columns_list: list):\n",
    "    for column in columns_list:\n",
    "        new_column= df[column].str.replace(pat='\\+( )+',repl= '+',regex= True).str.replace(pat= '-( )+', repl= '-',regex= True)\n",
    "        df[column]= pd.to_numeric(new_column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply shift and cut to the signal\n",
    "def shift_cut(df:pd.DataFrame):\n",
    "    Z_TCP_OK = 0\n",
    "    Z_Schlitten_OK = 0\n",
    "    Z_Hals_OK = 0\n",
    "    Z_Welle_OK = 0\n",
    "    n= 4\n",
    "    df['z_tcp_ok_orginal']= df['z_tcp_ok'].copy()\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"drhz\"] >=3000:\n",
    "            ###Get the values N steps before. This should be the 0 value\n",
    "            Z_TCP_OK= df['z_tcp_ok'][index - n]\n",
    "            Z_Schlitten_OK = df['z_schlitten_ok'][index - n]\n",
    "            Z_Hals_OK = df['z_hals_ok'][index - n]\n",
    "            Z_Welle_OK = df['z_welle_ok'][index - n]\n",
    "            ## Apply Shift\n",
    "            df['z_tcp_ok']= df['z_tcp_ok'] - Z_TCP_OK\n",
    "            df['z_schlitten_ok']= df['z_schlitten_ok'] - Z_Schlitten_OK\n",
    "            df['z_hals_ok']= df['z_hals_ok'] - Z_Hals_OK\n",
    "            df['z_welle_ok']= df['z_welle_ok'] - Z_Welle_OK\n",
    "            ## Apply cut\n",
    "            df= df[index -n :]\n",
    "            break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_dir in os.listdir(dir):\n",
    "    if os.path.isdir(os.path.join(dir, current_dir)):\n",
    "        print (current_dir)\n",
    "        os.chdir(os.path.join(dir, current_dir))\n",
    "    working_dir= str(dir+ current_dir+'\\\\')\n",
    "    #### Find relevant measure file#####\n",
    "    temp_file= None\n",
    "    for file in glob.glob('_N_*MPF.xlsx'):\n",
    "        if file is not None:\n",
    "            temp_file= file\n",
    "            break\n",
    "\n",
    "    #### Find relevant log file#####\n",
    "    log_file= None\n",
    "    for file in glob.glob('*.CSV'):\n",
    "        if re.match(pattern='^\\d.*\\d\\.CSV$',string= file) is not None:\n",
    "                log_file= file\n",
    "    if temp_file is None or log_file is None:\n",
    "        continue\n",
    "\n",
    "    print (\"First File: \", temp_file)\n",
    "    print (\"Second File: \", log_file)\n",
    "    ######Load file with 2 minutes sampling rate\n",
    "    df_measures= pd.read_excel(str(working_dir+temp_file),sheet_name=0, parse_dates= True, date_parser=dateparse)\n",
    "    df_measures['DAT_UHZ']= df_measures['DAT_UHZ'].apply(lambda t: t.replace(second=0))\n",
    "    to_drop= ['T_Bett', 'T_Spindel', 'DATUM', 'ZEIT','DAT_UHZ.1', 'count', 'Z_Schlitten_OK', 'Z_Hals_OK']\n",
    "    for column in df_measures.columns:\n",
    "        if str(column).find('Unnamed') != -1:\n",
    "            to_drop.append(column)\n",
    "    df_measures.drop(columns=to_drop, inplace=True)\n",
    "    df_measures.columns= df_measures.columns.str.lower()\n",
    "    df_measures_fields=  df_measures.columns.to_list()\n",
    "    print('Resulted fields: ')\n",
    "    print(df_measures_fields)\n",
    "    fields= \"\"\n",
    "    for field in df_measures_fields:\n",
    "        if fields == \"\":\n",
    "            fields = \"df_measures.\"+field\n",
    "        else:\n",
    "            fields += \", df_measures.\"+ field\n",
    "    df_measures_fields= fields\n",
    "#    print(df_measures.head(3))\n",
    "    file_path=str(dir+'output\\\\'+current_dir+'.csv')\n",
    "    df_measures['M8']= 1\n",
    "    df_measures['M121']= 0\n",
    "    df_measures['M127']= 0\n",
    "    df_measures['M7']= 0\n",
    "    df_measures.to_csv(file_path)\n",
    "    #####Load log file with 20 seconds sampling rate\n",
    "    content = open(str(working_dir+log_file)).readlines()\n",
    "    lines = [line_num for line_num, line_content in enumerate(content) if \"Data\" in line_content]\n",
    "    skipped_rows= list(range(0,lines[0]+1))\n",
    "    skipped_rows.append(lines[0]+2)\n",
    "    df_logs= pd.read_csv(str(working_dir+log_file), sep=',',skiprows= skipped_rows, infer_datetime_format= True, parse_dates= True, date_parser= dateparse)\n",
    "    # CH4=Vorlauftemperatur und CH3=Rücklauftemperatur (in der Datei steht es falsch herum)\n",
    "    # CH5=Volumenstrom kann man zur Dokumentationszwecken mitnehmen ist aber nicht notwendig\n",
    "    # Die Alarme haben keine Funktion und könnnen weglassen werden\n",
    "    df_logs.drop(columns=[\"Alarm1-10\",\"Alarm11-20\",\"AlarmOut\",\"ms\",\"Number\"], inplace=True)\n",
    "    df_logs.rename(columns={'Date&Time': 'time_stamp','CH1': 'T_KSS_TANK', 'CH2':'T_RAUM', 'CH3':'T_SPINDEL_RUECK', 'CH4':'T_SPINDEL_Vor', 'CH5':'Volumenstrom'}, inplace= True)#, 'CH6':\"T_Schwenkantrieb_Flansch\"\n",
    "    df_logs.columns= df_logs.columns.str.lower()\n",
    "    print(df_logs.columns)\n",
    "    df_logs= handle_special_numbers(df_logs, columns_list=['t_kss_tank', 't_raum', 't_spindel_vor','t_spindel_rueck', 'volumenstrom'])\n",
    "    df_logs_fields= df_logs.columns.to_list()\n",
    "    fields= \"\"\n",
    "    for field in df_logs_fields:\n",
    "        if fields == \"\":\n",
    "            fields = \"df_logs.\" + field\n",
    "        else:\n",
    "            fields += \", df_logs.\" + field\n",
    "    df_logs_fields= fields\n",
    "    ####Apply Query\n",
    "    query= \"\"\"\n",
    "    select * from \n",
    "    (\n",
    "    select df_measures.start as start, df_measures.end as end,{df_measures_columns}, min(df_logs.ts) as ts from \n",
    "        (\n",
    "        (select  {df_measures_columns}, strptime(df_measures.dat_uhz,'{df_m_date_format}') as start, (strptime(df_measures.dat_uhz,'{df_m_date_format}') + interval 2 Minute) as end   from df_measures) as df_measures\n",
    "        join\n",
    "        (select {df_logs_columns}, strptime(df_logs.time_stamp ,'{log_date_format}') as ts from df_logs) as df_logs\n",
    "        on (df_logs.ts >= df_measures.start) and ( df_logs.ts < df_measures.end)\n",
    "        )\n",
    "    group by df_measures.start, df_measures.end, {df_measures_columns}\n",
    "    ) combined_logs\n",
    "    join \n",
    "    df_logs\n",
    "    on (combined_logs.ts = strptime(df_logs.time_stamp ,'{log_date_format}'))\n",
    "    order by start Asc\n",
    "    \"\"\".format(df_measures_columns= df_measures_fields, df_logs_columns= df_logs_fields, df_m_date_format= df_measures_date_format, log_date_format= df_log_date_format)\n",
    "    results= ddb.query(query=query)\n",
    "    result_df= results.to_df()\n",
    "    \n",
    "    ###Insert cooling data\n",
    "    ###M8\n",
    "    if current_dir.find('_M8')== -1:\n",
    "        result_df['M8']= 0\n",
    "    else:\n",
    "        result_df['M8']= 1\n",
    "    ###M121\n",
    "    if current_dir.find('_M121')== -1:\n",
    "        result_df['M121']= 0\n",
    "    else:\n",
    "        result_df['M121']= 1\n",
    "    ###M127\n",
    "    if current_dir.find('_M127')== -1:\n",
    "        result_df['M127']= 0\n",
    "    else:\n",
    "        result_df['M127']= 1\n",
    "    ###M7\n",
    "    if current_dir.find('_M7')== -1:\n",
    "        result_df['M7']= 0\n",
    "    else:\n",
    "        result_df['M7']= 1\n",
    "    result_df['t_kuehlung']= result_df['t_spindel_vor']\n",
    "    result_df= shift_cut(result_df)\n",
    "    result_df.reset_index(inplace= True)\n",
    "    #result_df.drop(columns= ['level_0', 'index'], inplace= True)\n",
    "    plt.plot(result_df['z_welle_ok'], label= 'z_wellle_ok')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.plot(result_df['drhz'], label= 'DRHZ')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    #file_path=str(dir+current_dir+'\\\\'+current_dir+'.csv')\n",
    "    #file_path=str(dir+'output\\\\'+current_dir+'.csv')\n",
    "    #result_df.to_csv(file_path)\n",
    "    print('Result File saved ', file_path)\n",
    "    print ('-----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98516c4905fb8467ece250085a11958ff6a81ba629b2fa3655ee37336959c16d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
