{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Libraries\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from keras.models import Model, load_model\n",
    "import glob \n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DB Config\n",
    "host= \"DevEdgeV32\"\n",
    "port=27017\n",
    "all_data= True\n",
    "get_preprocessed_data= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/preprocessor/'\n",
    "preprocessor_name='preprocessor.p'\n",
    "model_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/model/'\n",
    "model_name= 'model.h5'\n",
    "model_input_Columns=  ['t_bett', 't_spindle','t_motor', 'M8','M121', 'M127', 'M7']#['t_bett','t_motor', 't_spindle','M8', 'M121', 'M127', 'M7']\n",
    "output_variable= 'welle_z'\n",
    "prediction_variable= 'prediction'\n",
    "time_shift= +1\n",
    "window=60\n",
    "response_time= 30\n",
    "time_relevance= 30\n",
    "recording_time= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove t_bett function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_t_bett(data: np.ndarray):\n",
    "    result= data[:, 1:]\n",
    "    result[:,0]= result[:,0] - data[:,0]\n",
    "    result[:,1]= result[:,1] - data[:,0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(signals: np.ndarray):\n",
    "    ##rounding t_motor to nearest integer\n",
    "    signals[:,1]= np.round(signals[:,1])\n",
    "    signals= np.round(signals, 2)\n",
    "    return signals\n",
    "\n",
    "def rounding2(signals: np.ndarray):\n",
    "    return np.round(signals, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "pipeline= load(str(preprocessor_dir+preprocessor_name))\n",
    "print('preprocessor is loaded successfully')\n",
    "model= load_model(str(model_dir + model_name), compile= False)\n",
    "print('Model is loaded successfully')\n",
    "print (model.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set time priod needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start= datetime.strptime(\"2022-09-20T22:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")# Trocken iso\n",
    "#end= datetime.strptime (\"2022-09-21T08:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "# start= datetime.strptime(\"2023-01-20T10:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") # Trocken Fräsen\n",
    "# end= datetime.strptime (\"2023-01-20T23:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "# start= datetime.strptime(\"2023-01-23T10:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\") # nass Fräsen\n",
    "# end= datetime.strptime (\"2023-01-23T17:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "#start= datetime.strptime(\"2023-01-31T17:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "#end= datetime.strptime (\"2023-01-31T23:59:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "start= datetime.strptime(\"2023-02-27T00:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "end= datetime.strptime (\"2023-03-03T00:59:59.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read raw and preprocessing data\n",
    "client = MongoClient(host= host, port=port)\n",
    "db = client.h4ai\n",
    "event_list = db.modelLogs.find({ \"date\" : { '$gte' : start, '$lt' : end} }).sort('date', 1)\n",
    "signals= None\n",
    "i=0\n",
    "last_prediction= -500\n",
    "### Go through events in DB\n",
    "for event in event_list:\n",
    "    i+=1\n",
    "    record_list= event['content']\n",
    "    keys= None\n",
    "    ### Go through records in each event\n",
    "    for record in record_list:\n",
    "    ##### Get only data points to be predicted\n",
    "        if not all_data:\n",
    "            if 'given2model' in record:\n",
    "                if not record['given2model']:\n",
    "                    continue\n",
    "            elif record[prediction_variable] == last_prediction:\n",
    "                continue\n",
    "            else:\n",
    "                last_prediction= record[prediction_variable]\n",
    "        #####\n",
    "        if 'given2model' in record:\n",
    "           record['raw_data']['given2model'] =record['given2model']\n",
    "        keys= record['raw_data'].keys()\n",
    "        for item in keys:\n",
    "            record['raw_data'][item]= [record['raw_data'][item]]\n",
    "        #print ('before',record)\n",
    "        record['raw_data']['date']=[record['date'] + timedelta(hours= time_shift)]\n",
    "        record['raw_data'][output_variable]=[record[output_variable]]\n",
    "        record['raw_data'][prediction_variable]=[record[prediction_variable]]\n",
    "        record['raw_data']['DRZ2']= float(record['DRZ2'])\n",
    "        #record['raw_data']['DRZ2'][0]= float(record['raw_data']['DRZ2'][0])\n",
    "        record['raw_data']['t_spindle'][0]= np.round(record['raw_data']['t_spindle'][0], decimals=2)\n",
    "        record['raw_data']['t_motor']= np.round(float(record['raw_data']['t_motor'][0]), decimals= 2)\n",
    "        #####Add preprocessed Data##########\n",
    "        if get_preprocessed_data:\n",
    "            record['raw_data']['0']= record['preprocessed_data'][0]\n",
    "            record['raw_data']['1']= record['preprocessed_data'][1]\n",
    "            record['raw_data']['2']= record['preprocessed_data'][2]\n",
    "            record['raw_data']['3']= record['preprocessed_data'][3]\n",
    "            record['raw_data']['4']= record['preprocessed_data'][4]\n",
    "            record['raw_data']['5']= record['preprocessed_data'][5]\n",
    "        ####################################\n",
    "        #print ('After ',record)\n",
    "        lf_signal_point= pd.DataFrame(record['raw_data'])\n",
    "        if signals is None:\n",
    "            signals= lf_signal_point\n",
    "        else:\n",
    "            signals= signals.append(lf_signal_point,ignore_index= True)\n",
    "signals['t_motor']= signals['t_motor'].apply(np.float32)\n",
    "# signals['db_prediction_abs_error']= signals[prediction_variable] -signals[output_variable]\n",
    "# signals['db_prediction_abs_error']= 1000 * signals['db_prediction_abs_error']\n",
    "signals.reset_index(inplace= True)\n",
    "####Apply enterpolation###\n",
    "upsampled_variable= output_variable#str('interpolated_'+output_variable)\n",
    "signals[upsampled_variable]= signals[output_variable]\n",
    "current_welle_z= 1000000\n",
    "for index, row in signals.iterrows():\n",
    "    if row[upsampled_variable]!= current_welle_z: ### A New value is available\n",
    "        current_welle_z= row[upsampled_variable]\n",
    "    else:\n",
    "        signals.at[index,upsampled_variable]= np.NaN\n",
    "signals[upsampled_variable].interpolate(method='linear', order=3, axis= 0,inplace= True)\n",
    "output=  signals[output_variable]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift the Z_Welle one step back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length= len(signals)\n",
    "# start= -1\n",
    "# end= -1\n",
    "# phases=[]\n",
    "# for index, row in signals.iterrows():\n",
    "#     if start<0:\n",
    "#         start= index\n",
    "#         continue\n",
    "#     if row['given2model'] or index == length - 1:\n",
    "#         end= index-1\n",
    "#         new_phase= (start, end)\n",
    "#         phases.append(new_phase)\n",
    "#         start= index\n",
    "#         #print(new_phase)\n",
    "# for phase in phases:\n",
    "#     start_idx= phase[0]\n",
    "#     end_idx= phase[1]\n",
    "#     print(phase)\n",
    "#     signals['welle_z'][start_idx: end_idx + 1]= signals['welle_z'][end_idx+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to extract M second array from n second array : M < n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_relevance_array(input_array: np.ndarray, output_shape):\n",
    "    input_time= input_array.shape[1] # in case of 5 Seconds it will be 240 seconds\n",
    "    output_time= output_shape[1] # in case of 2 Minutes it will be 10\n",
    "    step= int(input_time/output_time)\n",
    "    resut_array= np.zeros(output_shape)\n",
    "    for i in range( 0, output_time):\n",
    "        #print('place in result: ', output_time - i - 1, ' place in original: ', input_time - i*step -1)\n",
    "        resut_array[0, output_time - i - 1, :]= input_array[0, input_time - i*step -1,:]\n",
    "    return resut_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the prediction by passing values with 5 seconds (Input Buffer 2 Minutes, Input data 5 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simulate the prediction by passing values with 5 seconds ########\n",
    "num_model_features= 6\n",
    "preds= []\n",
    "input_data= signals.copy()\n",
    "shape=(1,window,num_model_features)\n",
    "output_sec_shape= (1, int(window*np.ceil((time_relevance/recording_time))), num_model_features)\n",
    "print('Requested buffer shape to the model= {}', shape)\n",
    "print('Orginal buffer shape to the model= {}', output_sec_shape)\n",
    "first_run= True\n",
    "inputsignal_list= model_input_Columns\n",
    "last_prediction_time= None\n",
    "out= 0\n",
    "prev_record_time= None\n",
    "for index, data_point in input_data.iterrows():\n",
    "    if prev_record_time is not None and (data_point['date']  - prev_record_time).total_seconds() < recording_time:\n",
    "        print('Escaped!')\n",
    "        #preds.append(out)\n",
    "        signals= signals[signals['date']!= data_point['date']]\n",
    "        continue\n",
    "    else:\n",
    "        prev_record_time= data_point['date']\n",
    "    #print ('index: ', index, ', Date: ', data_point['date'])\n",
    "    new_signal_list = [float(data_point[sig]) for sig in inputsignal_list]\n",
    "    #print ('New_signal_list: ', new_signal_list, ' timestamp: ', data_point['date'])\n",
    "    rough_input_array= np.asarray([new_signal_list])\n",
    "    signals_ = pipeline.transform(rough_input_array)#np.asarray([new_signal_list])#\n",
    "    if first_run:\n",
    "        #print ('index: ', index, ', Date: ', data_point['date'])\n",
    "        #print('time_ diff= ', str((data_point['date'] - last_prediction_time).total_seconds()))\n",
    "        # Auffüllen der Struktur - Bei erstem Start ist nur ein Datensatz vorhanden,\n",
    "        # dieser wird mit np.full in alle kopiert\n",
    "        five_sec_array= np.float32(np.full(output_sec_shape, signals_[0]))\n",
    "        array= extract_time_relevance_array(five_sec_array,shape)\n",
    "        #outputs = ort_sess.run(None, {'x': array})\n",
    "        outputs =model.predict(array)\n",
    "        #out = outputs[0][0][0] / 1000\n",
    "        out = outputs[0][0] / 1000\n",
    "        #print('Predciction First time. Input Buffer: ', array, 'prediction: ', out)\n",
    "        preds.append(out)\n",
    "        first_run = False\n",
    "        last_prediction_time= data_point['date']\n",
    "        #print('prediction_time: ', data_point['date'])\n",
    "        continue\n",
    "    elif (data_point['date'] - last_prediction_time).total_seconds()< response_time:\n",
    "            #print('No prediction. Just shift')\n",
    "            five_sec_array [0][:-1] = five_sec_array[0][1:]\n",
    "            five_sec_array[0, -1, :] = signals_[0]\n",
    "            preds.append(out)\n",
    "            continue \n",
    "    else:\n",
    "        #print ('index: ', index, ', Date: ', data_point['date'])\n",
    "        #print('time_ diff= ', str((data_point['date'] - last_prediction_time).total_seconds()))\n",
    "        #print(\"....Shifting the 5 seconds buffer and insert the new 5s-value\")\n",
    "        five_sec_array [0][:-1] = five_sec_array[0][1:]\n",
    "        five_sec_array[0, -1, :] = signals_[0]\n",
    "        array= extract_time_relevance_array(five_sec_array, shape)\n",
    "        array = np.float32(array)\n",
    "        ## Apply predicitions on 2 minutes buffer\n",
    "        outputs =model.predict(array)\n",
    "        #out = outputs[0][0][0] / 1000\n",
    "        out = outputs[0][0] / 1000\n",
    "        #print('Prediction Normal state. Input Buffer: ', array, 'prediction: ', out)\n",
    "        preds.append(out)\n",
    "        last_prediction_time= data_point['date']\n",
    "        #print('prediction_time: ', data_point['date'])\n",
    "    #signals['local_preds'][index]= out\n",
    "    #print(signals.iloc[index])\n",
    "    #print('#########################################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign local prediction to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signals[output_variable].mask(signals[output_variable]>0.05,0, inplace=True)\n",
    "signals['local_preds']= preds#[1:]\n",
    "local_prediction_error= signals[output_variable] - signals['local_preds']\n",
    "machine_prediction_error= signals[output_variable] - signals[prediction_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path='//Heller.biz/hnt/Steuerungstechnik/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed/AI_Model/Backup/Z_Welle/v2.7.0/five_seconds/'\n",
    "## Comparasion between two sources:\n",
    "from turtle import color\n",
    "scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "selected_Columns= ['t_bett','t_motor', 't_spindle' ,'given2model','DRZ2', 'M8', 'M121', 'M127', 'M7', prediction_variable]\n",
    "y_axis_names= selected_Columns\n",
    "#print(preds)\n",
    "fig= make_subplots(rows=len(selected_Columns)+1,cols=1,shared_xaxes= True, print_grid= True, subplot_titles= selected_Columns, vertical_spacing=0.02)\n",
    "for i in range(len(selected_Columns)):\n",
    "    fig.add_trace(go.Scatter(x= signals['date'], y= signals[selected_Columns[i]], name=selected_Columns[i], mode= scatter_mode), row= i+1, col= 1)\n",
    "    fig.update_yaxes(title_text= y_axis_names[i], row= i+1, col= 1)\n",
    "##Draw the prediciton and the real values of displacement on Welle\n",
    "fig.add_trace(go.Scatter(x= signals['date'],y= signals[output_variable], name=output_variable, mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y=  signals['local_preds'], name='Local predictions', mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.update_yaxes(title_text= output_variable, row= len(selected_Columns), col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y=   1000*local_prediction_error, name='New Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y=   1000*machine_prediction_error, name='Machine Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "## Draw the tolerence +-5\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(local_prediction_error,5), name='+5 Max Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(local_prediction_error,-5), name='-5 Min Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "\n",
    "#fig.add_trace(go.Scatter(x= signals['date'], y=   1000*( np.abs(signals[output_variable] - signals[prediction_variable])), name='Old Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.update_yaxes(title_text= 'Error (Micro-meter)', row= len(selected_Columns)+1, col= 1)\n",
    "fig.update_layout(height=1200, width=1400, title_text= 'Prediction Results')\n",
    "#pio.write_image(fig, str(images_path +'versuch_25_09_iso.png'), format='png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # images_path='//Heller.biz/hnt/Steuerungstechnik/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed/AI_Model/Backup/Z_Welle/v2.7.0/five_seconds/'\n",
    "# # ## Comparasion between two sources:\n",
    "# # from turtle import color\n",
    "# # scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "# # selected_Columns= [prediction_variable]\n",
    "# # y_axis_names= selected_Columns\n",
    "# # #print(preds)\n",
    "# # fig= make_subplots(rows=len(selected_Columns),cols=1,shared_xaxes= True, print_grid= True, subplot_titles= selected_Columns, vertical_spacing=0.02)\n",
    "# # for i in range(len(selected_Columns)):\n",
    "# #     fig.add_trace(go.Scatter(x= signals['date'], y= signals[selected_Columns[i]], name=selected_Columns[i], mode= scatter_mode), row= i+1, col= 1,)\n",
    "# #     fig.update_yaxes(title_text= y_axis_names[i], row= i+1, col= 1)\n",
    "# # ##Draw the prediciton and the real values of displacement on Welle\n",
    "# # fig.add_trace(go.Scatter(x= signals['date'],y= signals[output_variable], name=output_variable, mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "# # fig.add_trace(go.Scatter(x= signals['date'], y=  signals['local_preds'], name='Local predictions', mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "# # fig.update_yaxes(title_text= output_variable, row= len(selected_Columns), col= 1)\n",
    "\n",
    "# # fig.update_layout(height=1200, width=1400, title_text= 'Prediction Results')\n",
    "# # #pio.write_image(fig, str(images_path +'versuch_25_09_iso.png'), format='png')\n",
    "# fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "98516c4905fb8467ece250085a11958ff6a81ba629b2fa3655ee37336959c16d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
