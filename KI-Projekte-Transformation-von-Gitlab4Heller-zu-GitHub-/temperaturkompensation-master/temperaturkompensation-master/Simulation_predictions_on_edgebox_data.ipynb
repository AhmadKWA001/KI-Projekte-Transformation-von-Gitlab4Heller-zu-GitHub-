{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the generation of predctions on the machine and make comparasion between the results. (Simulation not just generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Libraries\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from keras.models import Model, load_model\n",
    "import glob \n",
    "import  pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####DB Config\n",
    "host= \"DevEdgeV32\"\n",
    "port=27017\n",
    "all_data= True\n",
    "get_preprocessed_data= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/data/_N_072221LOG_PLA3_MPF.csv'\n",
    "preprocessor_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/preprocessor/'\n",
    "preprocessor_name='preprocessor.p'\n",
    "model_dir='G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/assets/model/'\n",
    "model_name= 'model.h5'\n",
    "model_input_Columns=  ['t_bett','t_motor', 't_spindle','M8', 'M121', 'M127', 'M7']\n",
    "output_variable= 'welle_z'\n",
    "prediction_variable= 'prediction'\n",
    "window=10\n",
    "shift= 1\n",
    "time_shift= +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove t_bett function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_t_bett(data: np.ndarray):\n",
    "    result= data[:, 1:]\n",
    "    result[:,0]= result[:,0] - data[:,0]\n",
    "    result[:,1]= result[:,1] - data[:,0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(signals: np.ndarray):\n",
    "    return np.round(signals,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "pipeline= load(str(preprocessor_dir+preprocessor_name))\n",
    "print('preprocessor is loaded successfully')\n",
    "model= load_model(str(model_dir + model_name), compile= False)\n",
    "print('Model is loaded successfully')\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set time priod needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= datetime.strptime(\"2022-11-12T20:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")\n",
    "end= datetime.strptime (\"2022-11-13T13:00:00.000+0000\", \"%Y-%m-%dT%H:%M:%S.%f+0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read raw and preprocessing data\n",
    "client = MongoClient(host= host, port=port)\n",
    "db = client.h4ai\n",
    "event_list = db.modelLogs.find({ \"date\" : { '$gte' : start, '$lt' : end} }).sort('date', 1)\n",
    "signals= None\n",
    "i=0\n",
    "last_prediction= -500\n",
    "### Go through events in DB\n",
    "for event in event_list:\n",
    "    i+=1\n",
    "    record_list= event['content']\n",
    "    keys= None\n",
    "    ### Go through records in each event\n",
    "    for record in record_list:\n",
    "    ##### Get only data points to be predicted\n",
    "        if not all_data:\n",
    "            if 'given2model' in record:\n",
    "                if not record['given2model']:\n",
    "                    continue\n",
    "            elif record[prediction_variable] == last_prediction:\n",
    "                continue\n",
    "            else:\n",
    "                last_prediction= record[prediction_variable]\n",
    "        #####\n",
    "        if 'given2model' in record:\n",
    "           record['raw_data']['given2model'] =record['given2model']\n",
    "        keys= record['raw_data'].keys()\n",
    "        for item in keys:\n",
    "            record['raw_data'][item]= [record['raw_data'][item]]\n",
    "        #print ('before',record)\n",
    "        record['raw_data']['date']=[record['date'] + timedelta(hours= time_shift)]\n",
    "        record['raw_data'][output_variable]=[record[output_variable]]\n",
    "        record['raw_data'][prediction_variable]=[record[prediction_variable]]\n",
    "        record['raw_data']['DRZ2'][0]= float(record['raw_data']['DRZ2'][0])\n",
    "        record['raw_data']['t_spindle'][0]= np.round(record['raw_data']['t_spindle'][0], decimals=2)\n",
    "        record['raw_data']['t_motor']= np.round(float(record['raw_data']['t_motor'][0]), decimals= 2)\n",
    "        #####Add preprocessed Data##########\n",
    "        if get_preprocessed_data:\n",
    "            record['raw_data']['0']= record['preprocessed_data'][0]\n",
    "            record['raw_data']['1']= record['preprocessed_data'][1]\n",
    "            record['raw_data']['2']= record['preprocessed_data'][2]\n",
    "            record['raw_data']['3']= record['preprocessed_data'][3]\n",
    "            record['raw_data']['4']= record['preprocessed_data'][4]\n",
    "            record['raw_data']['5']= record['preprocessed_data'][5]\n",
    "        ####################################\n",
    "        #print ('After ',record)\n",
    "        lf_signal_point= pd.DataFrame(record['raw_data'])\n",
    "        if signals is None:\n",
    "            signals= lf_signal_point\n",
    "        else:\n",
    "            signals= signals.append(lf_signal_point,ignore_index= True)\n",
    "signals['t_motor']= signals['t_motor'].apply(np.float32)\n",
    "signals.reset_index(inplace= True)\n",
    "output=  signals[output_variable]\n",
    "machine_prediction= signals[prediction_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals['M8']= signals['M8'].shift(+3)\n",
    "signals=signals[4:]\n",
    "signals.reset_index(inplace= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift the Z_Welle one step back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length= len(signals)\n",
    "start= -1\n",
    "end= -1\n",
    "phases=[]\n",
    "for index, row in signals.iterrows():\n",
    "    if start<0:\n",
    "        start= index\n",
    "        continue\n",
    "    if row['given2model'] or index == length - 1:\n",
    "        end= index-1\n",
    "        new_phase= (start, end)\n",
    "        phases.append(new_phase)\n",
    "        start= index\n",
    "        print(new_phase)\n",
    "for phase in phases:\n",
    "    start_idx= phase[0]\n",
    "    end_idx= phase[1]\n",
    "    signals['welle_z'][start_idx: end_idx + 1]= signals['welle_z'][end_idx+1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the error after the correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals['db_prediction_abs_error']= signals[prediction_variable] -signals[output_variable]\n",
    "signals['db_prediction_abs_error']= 1000 * signals['db_prediction_abs_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the retreived data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "selected_Columns= ['DRZ2','t_motor', 't_spindle' ,'M8', 'M121', 'M127', 'M7','given2model', prediction_variable, output_variable, 'db_prediction_abs_error']\n",
    "y_axis_names= selected_Columns\n",
    "#print(preds)\n",
    "fig= make_subplots(rows=10,cols=1,shared_xaxes= True, print_grid= True, vertical_spacing=0.02)\n",
    "##t_bett\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['DRZ2'], name='DRZ2', mode= scatter_mode), row= 1, col= 1)\n",
    "fig.update_yaxes(title_text= 'DRZ2', row= 1, col= 1)\n",
    "##t_motor\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['t_motor'], name='t_motor', mode= scatter_mode), row= 2, col= 1)\n",
    "fig.update_yaxes(title_text= 't_motor C°', row= 2, col= 1)\n",
    "##t_spindel\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['t_spindle'], name='t_spindel', mode= scatter_mode), row= 3, col= 1)\n",
    "fig.update_yaxes(title_text= 't_spindel C°', row= 3, col= 1)\n",
    "##'M8'\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['M8'], name='M8', mode= scatter_mode), row= 4, col= 1)\n",
    "fig.update_yaxes(title_text= 'M8 0/1', row= 4, col= 1)\n",
    "##'M121'\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['M121'], name='M121', mode= scatter_mode), row= 5, col= 1)\n",
    "fig.update_yaxes(title_text= 'M121 0/1', row= 5, col= 1)\n",
    "##'M127'\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['M127'], name='M127', mode= scatter_mode), row= 6, col= 1)\n",
    "fig.update_yaxes(title_text= 'M127 0/1', row= 6, col= 1)\n",
    "##'M7'\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['M7'], name='M7', mode= scatter_mode), row= 7, col= 1)\n",
    "fig.update_yaxes(title_text= 'M7 0/1', row= 7, col= 1)\n",
    "##'given2model'\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['given2model'], name='given2model', mode= scatter_mode), row= 8, col= 1)\n",
    "fig.update_yaxes(title_text= 'given2model 0/1', row= 8, col= 1)\n",
    "##Verlagerung\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= 1000 * signals[output_variable], name='Gemesene Verlagerung (Welle)', mode= scatter_mode), row= 9, col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= 1000 * signals[prediction_variable], name='KI-basierte Verlagerung (Welle)', mode= scatter_mode), row= 9, col= 1)\n",
    "fig.update_yaxes(title_text= 'Verlagerung Micro-Meter', row= 9, col= 1)\n",
    "##Restfehler\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= signals['db_prediction_abs_error'], name=' Restfehler', mode= scatter_mode),  row= 10 , col= 1)\n",
    "## Draw the tolerence +-5\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(signals['db_prediction_abs_error'],5), name='+5 Obere Grenze', mode= scatter_mode),  row= 10 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(signals['db_prediction_abs_error'],-5), name='- 5 Obere Grenze', mode= scatter_mode),  row= 10 , col= 1)\n",
    "fig.update_yaxes(title_text= output_variable, row= 10, col= 1)\n",
    "fig.update_layout(height=1200, width=1400, title_text= 'M57002 Machine Data')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_signals= signals[model_input_Columns].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the prediction by passing values with 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simulate the prediction by passing values with 5 seconds ########\n",
    "preds= []\n",
    "#selected_Columns=  ['0','1','2','3','4','5']\n",
    "input_data= signals\n",
    "shape=(1,window,6)\n",
    "first_run= True\n",
    "# signal liste für preprocessing erstellen (Reihenfolge wie in input_signals im config-File)\n",
    "signaloffsetnumber = 0\n",
    "inputsignal_list= model_input_Columns\n",
    "recording_frequency= 120\n",
    "# 2 Minuten-Problem\n",
    "time_point = input_data['date'][0]#datetime.utcnow()\n",
    "time_point_dbwait = input_data['date'][0]#datetime.utcnow()\n",
    "under_2_min = True\n",
    "dbwrite_wait = True\n",
    "go_on_prog = True\n",
    "hlpvar = False\n",
    "prev_input= None\n",
    "before_prev_input= prev_input\n",
    "out=0\n",
    "predicted= False\n",
    "for index, data_point in input_data.iterrows():\n",
    "    predicted= False\n",
    "    #print ('index: ', index, ', point: ', data_point)\n",
    "    meas_trigger= data_point['given2model']\n",
    "    current_time_2min = data_point['date']\n",
    "    under_2_min = (current_time_2min - time_point).total_seconds() <= recording_frequency  # 120 #120\n",
    "    #if meas_trigger:\n",
    "        # ### correct last value of prediction\n",
    "        # # 1- Correct cooling values in previous time step t-1 to be as t-2\n",
    "        # signals.loc[index - 1,'M8']= before_prev_input['M8']\n",
    "        # signals.loc[index - 1,'M121']= before_prev_input['M121']\n",
    "        # signals.loc[index - 1,'M127']= before_prev_input['M127']\n",
    "        # signals.loc[index - 1,'M7']= before_prev_input['M7']\n",
    "        # # 1- Correct cooling values of the current time step t to be as t-2\n",
    "        # signals.loc[index ,'M8']= before_prev_input['M8']\n",
    "        # signals.loc[index ,'M121']= before_prev_input['M121']\n",
    "        # signals.loc[index ,'M127']= before_prev_input['M127']\n",
    "        # signals.loc[index ,'M7']= before_prev_input['M7']\n",
    "        # data_point[['M8', 'M121', 'M127', 'M7']]= before_prev_input[['M8', 'M121', 'M127', 'M7']]\n",
    "        #print ('index: ', index, ', updated point: ', data_point)\n",
    "    new_signal_list = [float(data_point[sig]) for sig in inputsignal_list]\n",
    "    #print ('New_signal_list: ', new_signal_list)\n",
    "    signals_ = pipeline.transform(np.asarray([new_signal_list]))#np.asarray([new_signal_list])#\n",
    "    #current_time_dbwait = datetime.utcnow()\n",
    "    #dbwrite_wait = (current_time_dbwait - time_point_dbwait).total_seconds() <= 120 #120\n",
    "    if first_run:\n",
    "        # Auffüllen der Struktur - Bei erstem Start ist nur ein Datensatz vorhanden,\n",
    "        # dieser wird mit np.full in alle kopiert\n",
    "        array = np.full(shape, signals_[0])\n",
    "        array = np.float32(array)\n",
    "        #outputs = ort_sess.run(None, {'x': array})\n",
    "        outputs =model.predict(array)\n",
    "        #out = outputs[0][0][0] / 1000\n",
    "        out = outputs[0][0] / 1000\n",
    "        #print('Predciction First time. Input Buffer: ', array, 'prediction: ', out)\n",
    "        predicted= True\n",
    "        preds.append(out)\n",
    "        first_run = False\n",
    "        continue\n",
    "    elif under_2_min:\n",
    "        #print('under2min 2: ')\n",
    "        #print('Buffer new state in under2min 2: ', array)\n",
    "        ### Just add last prediction\n",
    "        if meas_trigger: #not dbwrite_wait:\n",
    "            #print(\"....durchshiften Pos1\")\n",
    "            #print('Buffer Current state before Shift: ', array)\n",
    "            array[0][:-1] = array[0][1:]\n",
    "            array[0, -1, :] = signals_[0]\n",
    "            #print('Buffer new  state After Shift: ', array)\n",
    "            #print ('under 2 min, meas_trigger True')\n",
    "    else:\n",
    "        #print ('under 2 min False')\n",
    "        # durchshiften der gelesenen Daten im array - FiFo\n",
    "        if meas_trigger: #not dbwrite_wait:\n",
    "           # print ('under 2 min False, meas_trigger True')\n",
    "            #print(\"....durchshiften Pos2\")\n",
    "           # print('Buffer Current state before Shift: ', array)\n",
    "            array[0][:-1] = array[0][1:]\n",
    "            array[0, -1, :] = signals_[0]\n",
    "            #print('Buffer new  state After Shift: ', array)\n",
    "            #time_point_dbwait = current_time_dbwait\n",
    "            #hlpvar = True\n",
    "        time_point = current_time_2min\n",
    "        #time_point_dbwait = current_time_dbwait\n",
    "    \n",
    "    if not (under_2_min and go_on_prog) or hlpvar or meas_trigger:\n",
    "        # if show_debugprints:\n",
    "            # print(f\"current input data: {array}\")\n",
    "        if meas_trigger: #hlpvar:\n",
    "            array = np.float32(array)\n",
    "            # entfernt, und nach ober vor while verschoben 17.06.22/gst ort_sess = ort.InferenceSession(model)\n",
    "            # Aufrufen der inference-Funktion von Mustafa.d.h hier wird aus den Werten die prediction erzeugt\n",
    "            outputs =model.predict(array)\n",
    "            #out = outputs[0][0][0] / 1000\n",
    "            out = outputs[0][0] / 1000\n",
    "            #print('Prediction Normal state. Input Buffer: ', array, 'prediction: ', out)\n",
    "            predicted= True\n",
    "            preds.append(out)\n",
    "    if not predicted:\n",
    "        preds.append(out)\n",
    "    before_prev_input= prev_input    \n",
    "    prev_input= data_point\n",
    "    #print('#########################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signals[output_variable]= signals[output_variable].shift(+1)# + 0.001441305# +2.54* 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign local prediction to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals['local_preds']= preds\n",
    "local_prediction_error= signals[output_variable] - signals['local_preds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path='//Heller.biz/hnt/Steuerungstechnik/Innovations@HELLER/DN/KI/Temperaturkompensation/2021_Spindelwachstumskompensation_KI_HSU_SC63/Messungen DC100 H5000 M57002/csvs/smoothed/AI_Model/Backup/Z_Welle/v2.7.0/five_seconds/'\n",
    "## Comparasion between two sources:\n",
    "from turtle import color\n",
    "scatter_mode= 'lines'#'lines'# 'lines+markers'# 'markers'\n",
    "selected_Columns= ['t_bett','t_motor', 't_spindle' ,'M8', 'M121', 'M127', 'M7','given2model', prediction_variable]\n",
    "y_axis_names= selected_Columns\n",
    "#print(preds)\n",
    "fig= make_subplots(rows=len(selected_Columns)+1,cols=1,shared_xaxes= True, print_grid= True, subplot_titles= selected_Columns, vertical_spacing=0.02)\n",
    "for i in range(len(selected_Columns)):\n",
    "    fig.add_trace(go.Scatter(x= signals['date'], y= signals[selected_Columns[i]], name=selected_Columns[i], mode= scatter_mode), row= i+1, col= 1,)\n",
    "    fig.update_yaxes(title_text= y_axis_names[i], row= i+1, col= 1)\n",
    "##Draw the prediciton and the real values of displacement on Welle\n",
    "fig.add_trace(go.Scatter(x= signals['date'],y= signals[output_variable], name=output_variable, mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y=  signals['local_preds'], name='Local predictions', mode= scatter_mode),  row= len(selected_Columns) , col= 1)\n",
    "fig.update_yaxes(title_text= output_variable, row= len(selected_Columns), col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y=   1000*local_prediction_error, name='New Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "## Draw the tolerence +-5\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(local_prediction_error,5), name='+5 Max Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.add_trace(go.Scatter(x= signals['date'], y= np.full_like(local_prediction_error,-5), name='-5 Min Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "\n",
    "#fig.add_trace(go.Scatter(x= signals['date'], y=   1000*( np.abs(signals[output_variable] - signals[prediction_variable])), name='Old Model prediction Error', mode= scatter_mode),  row= len(selected_Columns)+1 , col= 1)\n",
    "fig.update_yaxes(title_text= 'Error (Micro-meter)', row= len(selected_Columns)+1, col= 1)\n",
    "fig.update_layout(height=1200, width=1400, title_text= 'Prediction Results')\n",
    "#pio.write_image(fig, str(images_path +'versuch_20_09_iso.png'), format='png')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a58a25343f99ae6e283c189afd7abc602dec6c63d356cacabf499812ae322086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
