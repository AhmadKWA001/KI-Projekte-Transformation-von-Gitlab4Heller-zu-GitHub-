{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "%load_ext tensorboard\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from joblib import dump, load\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "import tf2onnx\n",
    "import onnx\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from joblib import dump, load\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM,Dense, GaussianNoise, BatchNormalization, Activation, PReLU, Dropout\n",
    "from keras.losses import mean_absolute_error as mae, mean_squared_error as mse, mean_absolute_percentage_error as mape\n",
    "from keras.optimizers import nadam_v2, rmsprop_v2, adamax_v2\n",
    "from keras.activations import silu,swish, linear, tanh,leaky_relu, sigmoid, relu,elu, selu, gelu, linear\n",
    "from keras.regularizers import l1, l2, L1L2\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_preprocess(data: np.ndarray):\n",
    "    delta_t_spindel_bett= data[:,1] - data[:,0]\n",
    "    delta_t_spindel_bett= delta_t_spindel_bett.reshape((-1,1))\n",
    "    result= np.concatenate(( data[:,2:5], delta_t_spindel_bett), axis=1)\n",
    "    return result\n",
    "\n",
    "def rounding(signals: np.ndarray):\n",
    "    return np.round(signals,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set parameters\n",
    "\n",
    "\n",
    "main_path= 'G:/Innovations@HELLER/DN/KI/Temperaturkompensation/New_Experiments/feature_generation/'\n",
    "generated_feature='t_motor'\n",
    "source_dir= main_path+ generated_feature+ '/problem_with_t_motor/'\n",
    "target_dir=source_dir+'/corrected/'\n",
    "main_dir= 'G:\\\\Innovations@HELLER\\\\DN\\\\KI\\\\Temperaturkompensation\\\\2021_Spindelwachstumskompensation_KI_HSU_SC63\\\\Messungen DC100 H5000 M57002\\\\csvs\\\\smoothed\\\\AI_Model\\\\Backup\\\\t_motor\\\\assets\\\\'\n",
    "model_dir= main_dir + 'model\\\\'\n",
    "preprocessor_dir= main_dir + 'preprocessor\\\\'\n",
    "model_name= 'model.h5'\n",
    "scaler= StandardScaler(with_mean= True, with_std= True)\n",
    "minmax= MinMaxScaler(feature_range=(-1,1))\n",
    "pca= PCA(n_components=1)\n",
    "##Data Parameters\n",
    "selected_Columns= ['t_spindel','drhz']#,'M8','M121','M127','M7','t_kuehlung']#['t_motor','DRZ']\n",
    "window=15\n",
    "shift= 1\n",
    "proposed_pipline= Pipeline(steps=[('stdscaler', scaler), ('pca', pca)])# Pipeline(steps=[('stdscaler', scaler),('special', FunctionTransformer(rounding))])# \n",
    "preprocessor_name= \"preprocessor.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataSource(signal_input= None, input_columns: list = [], output_length: int=1, signal_output= None, window= 1 , shift= 1):\n",
    "    Signal_Length = signal_input.shape[0]\n",
    "    num_samples= int((Signal_Length - window +1 ) / shift)\n",
    "    x = np.zeros(shape=(num_samples, window, signal_input.shape[1]))\n",
    "    y= np.zeros(shape=(num_samples, output_length, 1))\n",
    "    for i in range (num_samples):\n",
    "        x[i]= signal_input[i * shift : i * shift + window]\n",
    "        y[i]= signal_output[i * shift + window - 1 : i * shift + window - 1+ output_length]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load models\n",
    "pipeline= load(str(preprocessor_dir+preprocessor_name))\n",
    "print('preprocessor is loaded successfully')\n",
    "model= load_model(str(model_dir + model_name), compile= False)\n",
    "print('Model is loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= ['t_bett', 't_spindel',\n",
    "       't_welle', 't_schlitten', 'drhz', 'z_schlitten_mk', 'z_schlitten_ok',\n",
    "       'z_hals_mk', 'z_hals_ok', 'z_spindel_mk', 'z_spindel_ok',\n",
    "       't_motor', 'pred_t_motor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline= load(str(preprocessor_dir+preprocessor_name))\n",
    "print('preprocessor is loaded successfully')\n",
    "#model= load_model(str(model_dir), compile= False)\n",
    "model_dir='G:\\\\Innovations@HELLER\\\\DN\\\\KI\\\\Temperaturkompensation\\\\2021_Spindelwachstumskompensation_KI_HSU_SC63\\\\Messungen DC100 H5000 M57002\\\\csvs\\\\smoothed\\\\AI_Model\\\\Backup\\\\t_motor\\\\assets\\\\model\\\\model.h5'\n",
    "model= load_model(model_dir, compile= False)\n",
    "print('Model is loaded successfully ')\n",
    "os.chdir(source_dir)\n",
    "for file in glob.glob('*.csv'):\n",
    "    if file == 'combined.csv':\n",
    "        continue\n",
    "    print('Current File: ', file)\n",
    "    df= pd.read_csv(file)\n",
    "    signals= df\n",
    "    signals= signals[selected_Columns].to_numpy()\n",
    "    signals= pipeline.transform(signals)\n",
    "    output= df['t_motor']\n",
    "    partitions, target= generateDataSource(signal_input= signals, input_columns= selected_Columns, output_length= 1,signal_output= output, window= window, shift= shift)\n",
    "    print('input: ', partitions.shape, ' output:', target.shape)\n",
    "    pred= model.predict(partitions)\n",
    "    print (df.columns)\n",
    "    df= df[window-1:]\n",
    "    print (df.shape)\n",
    "    print (pred.shape)\n",
    "    df['t_motor']= pred\n",
    "    df.to_csv(path_or_buf=str(target_dir+'corrected_'+file))\n",
    "    #df2= pd.DataFrame({'targets': np.reshape(target,-1), 'pred': np.reshape(pred,-1)})\n",
    "    fig= ex.line(df,y=['t_motor'])\n",
    "    #fig.update_layout(height=1200, width=1200, title_text=\"Laser-Data\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize Results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a58a25343f99ae6e283c189afd7abc602dec6c63d356cacabf499812ae322086"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
